[
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test for stored secrets",
    "Level": "1",
    "Description": "Testing for stored secrets involves verifying that sensitive information, such as API keys, passwords, and certificates, are securely stored and not exposed in code repositories or configuration files. This practice prevents unauthorized access and potential security breaches. Tools like GitSecrets, TruffleHog, and Vault can be integrated into DevSecOps pipelines to automate the detection and secure storage of secrets.",
    "Tools": [
      {
        "Name": "GitSecrets",
        "Description": "A tool that scans Git repositories for sensitive information and prevents commits containing secrets, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "TruffleHog",
        "Description": "Searches through Git repositories for high-entropy strings and secrets, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Vault",
        "Description": "A tool for securely storing and accessing secrets, integrated into CI/CD pipelines to manage sensitive information.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Stored secrets in git history, in container images or directly in code shouldn't exists because they might be exposed to unauthorized parties.",
    "Measure": "Test for secrets in code, container images and history",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "9/30/2002",
    "ISO 27001:2022": "vcs usage is not explicitly covered by ISO 27001 - too specific,5.17,8.24"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Baseline Hardening of the environment",
    "Level": "2",
    "Description": "Baseline hardening of the environment involves establishing a secure configuration baseline for systems and infrastructure components. This ensures that all environments adhere to organizational security standards and reduces the risk of vulnerabilities. Pipeline-compatible tools like Ansible, Puppet, and Chef can automate the enforcement of baseline configurations within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Ansible",
        "Description": "Automation tool that can enforce baseline security configurations across multiple systems within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["YAML"]
      },
      {
        "Name": "Puppet",
        "Description": "Configuration management tool that automates the application of baseline security standards across environments.",
        "Opensource": true,
        "Languages": ["Ruby"]
      },
      {
        "Name": "Chef",
        "Description": "Automation platform that can manage and enforce baseline security configurations within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["Ruby"]
      }
    ],
    "Risk": "Using default configurations for a cluster environment leads to potential risks.",
    "Measure": "Harden environments according to best practices. Level 1 and partially level 2 from hardening practices like 'CIS Kubernetes Bench for Security' should be considered.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Security consulting on request",
    "Level": "1",
    "Description": "Providing security consulting on request involves offering expert guidance and support to teams as needed to address specific security challenges or queries. This ensures that teams have access to specialized knowledge when implementing security measures. Pipeline-compatible tools like Slack and Microsoft Teams can facilitate communication and consultation requests within CI/CD workflows.",
    "Tools": [],
    "Risk": "Not asking a security expert when questions regarding security appear might lead to flaws.",
    "Measure": "Security consulting to teams is given on request. The security consultants can be internal or external.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "G-EG-1-A",
    "ISO 27001:2017": "6.1.1",
    "ISO 27001:2022": "Security consulting is missing in ISO 27001 may be,5.2,5.6,5.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage analysis",
    "Level": "5",
    "Description": "Coverage analysis in dynamic testing assesses how much of the application's code is exercised during testing. It helps identify untested parts of the codebase, ensuring comprehensive testing and reducing the risk of undiscovered vulnerabilities. Tools like JaCoCo, Istanbul, Coverage.py, and Codecov can aid in measuring and visualizing code coverage.",
    "Tools": [
      {
        "Name": "JaCoCo",
        "description": "Java code coverage library.",
        "opensource": true,
        "languages": ["Java"]
      },
      {
        "Name": "Istanbul",
        "description": "JavaScript code coverage tool.",
        "opensource": true,
        "languages": ["JavaScript"]
      },
      {
        "Name": "Coverage.py",
        "description": "Code coverage measurement for Python.",
        "opensource": true,
        "languages": ["Python"]
      },
      {
        "Name": "Clover",
        "description": "Code coverage tool for Java and Groovy.",
        "opensource": false,
        "languages": ["Java", "Groovy"]
      },
      {
        "Name": "Bullseye",
        "description": "Code coverage tool for C and C++.",
        "opensource": false,
        "languages": ["C", "C++"]
      },
      {
        "Name": "DotCover",
        "description": "Code coverage tool for .NET applications.",
        "opensource": false,
        "languages": [".NET"]
      },
      {
        "Name": "Cobertura",
        "description": "Java tool for measuring test coverage.",
        "opensource": true,
        "languages": ["Java"]
      },
      {
        "Name": "Codecov",
        "description": "Cloud service for code coverage reports.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Coveralls",
        "description": "Web service to track code coverage over time.",
        "opensource": false,
        "languages": []
      }
    ],
    "Risk": "Parts of the service are not still covered by tests.",
    "Measure": "Check that there are no missing paths in the application with coverage-tools.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "High",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "not explicitly covered by ISO 27001 - too specific",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Reward of good communication",
    "Level": "2",
    "Description": "Rewarding good communication involves recognizing and incentivizing effective information sharing and collaboration among team members. This fosters a culture of transparency, encourages proactive security practices, and enhances overall team cohesion. Pipeline-compatible tools like Slack and Microsoft Teams can facilitate communication, while platforms like Bonusly can manage rewards and recognition within CI/CD workflows.",
    "Tools": [],
    "Risk": "Employees are not getting excited about security.",
    "Measure": "Good communication and transparency encourages cross-organizational support. Gamification of security is also known to help, examples include T-Shirts, mugs, cups, gift cards and 'High-Fives'.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "G-EG-1-B",
    "ISO 27001:2017": "interestingly enough A7.2.3 is requiring a process to handle misconduct but nothing to promote good behavior.",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Coverage and control metrics",
    "Level": "4",
    "Description": "Monitoring coverage and control metrics involves tracking various security-related metrics to assess the effectiveness of security controls and identify areas needing improvement. This ensures continuous improvement and compliance with security standards. Tools such as Prometheus, Grafana, Datadog, New Relic, Splunk, Nagios, and the ELK Stack can be utilized for comprehensive metric monitoring and visualization.",
    "Tools": [
      {
        "Name": "Prometheus",
        "description": "Open-source monitoring and alerting toolkit.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Grafana",
        "description": "Open-source platform for monitoring and observability.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Datadog",
        "description": "Monitoring and analytics platform for developers and IT operations.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "New Relic",
        "description": "Application performance monitoring and analytics.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Splunk",
        "description": "Platform for searching, monitoring, and analyzing machine-generated data.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Nagios",
        "description": "Open-source monitoring system for networks, applications, and infrastructure.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Zabbix",
        "description": "Enterprise-class open-source monitoring solution.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "description": "Comprehensive logging and monitoring solution.",
        "opensource": true,
        "languages": []
      }
    ],
    "Risk": "The effectiveness of configuration, patch and vulnerability management is unknown.",
    "Measure": "Usage of Coverage- and control-metrics to show the effectiveness of the security program. Coverage is the degree in which a specific security control for a specific target group is applied with all resources. The control degree shows the actual application of security standards and security-guidelines. Examples are gathering information on anti-virus, anti-rootkits, patch management, server configuration and vulnerability management.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "not explicitly covered by ISO 27001 - too specific",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage of hidden endpoints",
    "Level": "3",
    "Description": "Coverage of hidden endpoints involves testing and verifying endpoints that are not immediately visible or documented in the application's API. This ensures that all potential access points are secured and free from vulnerabilities. Tools like Burp Suite, OWASP ZAP, Postman, SoapUI, Fiddler, and Insomnia can assist in discovering and testing these hidden endpoints.",
    "Tools": [
      {
        "Name": "Burp Suite",
        "description": "Integrated platform for performing security testing of web applications.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "OWASP ZAP",
        "description": "Open-source web application security scanner.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Postman",
        "description": "API development and testing tool.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "SoapUI",
        "description": "Tool for testing SOAP and REST web services.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Fiddler",
        "description": "Web debugging proxy for monitoring and modifying HTTP/HTTPS traffic.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Insomnia",
        "description": "Open-source API client for REST and GraphQL.",
        "opensource": true,
        "languages": []
      }
    ],
    "Risk": "Hidden endpoints of the service are not getting tracked.",
    "Measure": "Hidden endpoints are getting detected and included in the vulnerability scan.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "not explicitly covered by ISO 27001 - too specific",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage of more input vectors",
    "Level": "3",
    "Description": "Coverage of more input vectors involves testing applications with a wide range of input data to identify potential vulnerabilities and ensure the application can handle unexpected or malicious inputs securely. Tools like FuzzDB, Burp Suite Intruder, OWASP ZAP Fuzzer, Radamsa, Wfuzz, AFL (American Fuzzy Lop), and Peach Fuzzer can facilitate comprehensive input vector testing.",
    "Tools": [
      {
        "Name": "FuzzDB",
        "description": "A comprehensive database of attack patterns, predictable resource locations, and more for application security testing.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Burp Suite Intruder",
        "description": "Automated tool for performing fuzzing and other injection attacks.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "OWASP ZAP Fuzzer",
        "description": "Fuzzing tool within OWASP ZAP for dynamic application testing.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Radamsa",
        "description": "Test case generator for robustness testing and fuzzing.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Wfuzz",
        "description": "Web application brute forcer and fuzzing tool.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "AFL (American Fuzzy Lop)",
        "description": "Security-oriented fuzzer for finding vulnerabilities in software.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Peach Fuzzer",
        "description": "Comprehensive fuzzing framework for testing applications.",
        "opensource": false,
        "languages": []
      }
    ],
    "Risk": "Parts of the service are not covered. For example specially formatted or coded parameters are not getting detected as parameter (e.g. parameters in REST-like URLs, parameters in JSON-Format or base64-coded parameters).",
    "Measure": "Special parameter and special encodings are defined, so that they get fuzzed by the used vulnerability scanners.",
    "Knowledge": "",
    "Resources": "Low",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "not explicitly covered by ISO 27001 - too specific",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Usage of different roles",
    "Level": "2",
    "Description": "Implementing the usage of different roles involves defining and enforcing role-based access controls (RBAC) within the application to ensure that users have appropriate permissions based on their roles. This enhances security by limiting access to sensitive functionalities and data. Pipeline-compatible tools like Auth0, Okta, and AWS IAM can automate the enforcement of role-based access controls within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Auth0",
        "Description": "Identity management platform that provides RBAC features to enforce role-based access controls within applications.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Okta",
        "Description": "Identity and access management service that supports RBAC to control user permissions based on roles.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "AWS IAM (Identity and Access Management)",
        "Description": "Identity and Access Management service that allows defining roles and policies to enforce RBAC within AWS environments.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Parts of the service are not covered during the scan, because a login is not performed.",
    "Measure": "Integration of authentication with all roles used in the service.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "Medium",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Metrics are combined with tests",
    "Level": "5",
    "Description": "Combining metrics with tests involves integrating performance and security metrics into the testing process to provide a more comprehensive evaluation of the application's behavior and security posture. This approach enables better decision-making based on quantitative data. Tools like Grafana, Prometheus, Datadog, New Relic, ELK Stack, and Splunk can be used to visualize and analyze combined metrics and test results.",
    "Tools": [
      {
        "Name": "Grafana",
        "description": "Open-source platform for monitoring and observability, allowing integration with various metrics and testing tools.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Prometheus",
        "description": "Monitoring system and time series database that can be integrated with testing frameworks.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Datadog",
        "description": "Monitoring and analytics platform that integrates with testing tools to combine metrics and test results.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "New Relic",
        "description": "Application performance monitoring tool that can combine metrics with testing data.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "description": "Comprehensive logging and monitoring solution that can integrate with test metrics.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Splunk",
        "description": "Platform for searching, monitoring, and analyzing machine-generated data, including test metrics.",
        "opensource": false,
        "languages": []
      }
    ],
    "Risk": "Changes might cause high load due to programming errors.",
    "Measure": "Metrics during tests helps to identify programming errors.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "not explicitly covered by ISO 27001",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Reduction of the attack surface",
    "Level": "2",
    "Description": "Reducing the attack surface involves minimizing the number of entry points and potential vulnerabilities in a system. This is achieved by disabling unnecessary services, removing unused software, and limiting exposed interfaces to decrease the opportunities for attackers.",
    "Tools": [
      {
        "Name": "Microsoft Baseline Security Analyzer (MBSA)",
        "description": "Scans Windows systems for missing security updates and common security misconfigurations.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "OpenVAS",
        "description": "Open-source vulnerability scanner and manager.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Nessus",
        "description": "Comprehensive vulnerability scanning tool.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Qualys",
        "description": "Cloud-based security and compliance solutions, including attack surface reduction.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Tripwire",
        "description": "Security and compliance automation tool for reducing attack surfaces.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Sysinternals Suite",
        "description": "Collection of utilities to manage, troubleshoot, and diagnose Windows systems.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Lynis",
        "description": "Security auditing tool for Unix-based systems.",
        "opensource": true,
        "languages": []
      }
    ],
    "Risk": "Components, dependencies, files or file access rights might have vulnerabilities, but the they are not needed.",
    "Measure": "Removal of unneeded components, dependencies, files or file access rights. For container images the usage of distroless images is recommended.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "I-SB-2",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "8.25"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Conduction of war games",
    "Level": "4",
    "Description": "Conducting war games involves simulating real-world cyberattack scenarios to test the organization's incident response capabilities and identify potential security weaknesses. This practice enhances preparedness, improves coordination among teams, and strengthens overall security posture. Pipeline-compatible tools like SimSpace and BattleEye can facilitate the automation and integration of war games within CI/CD pipelines.",
    "Tools": [],
    "Risk": "Understanding incident response plans during an incident is hard and ineffective.",
    "Measure": "War Games like activities help train for incidents. Security SMEs create attack scenarios in a testing environment enabling the trainees to learn how to react in case of an incident.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Very High",
    "Time": "",
    "Usefulness": "High",
    "SAMM": "G-EG-2-A",
    "ISO 27001:2017": "16.1.5",
    "ISO 27001:2022": "War games are not explicitly required in ISO 27001 may be,6.3,5.24,5.26"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Applications are running in virtualized environments",
    "Level": "2",
    "Description": "Running applications in virtualized environments involves deploying applications within virtual machines or containers to enhance scalability, flexibility, and security. This approach allows for efficient resource utilization and isolation of applications, reducing the risk of cross-application vulnerabilities. Pipeline-compatible tools like Docker, Kubernetes, and VMware vSphere can automate the deployment and management of applications within virtualized environments in CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Docker",
        "Description": "Platform for developing, shipping, and running applications in containers, essential for deploying applications in virtualized environments within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that manages the deployment and scaling of applications within virtualized environments in CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "VMware vSphere",
        "Description": "Virtualization platform for managing virtual machines and deploying applications within isolated environments.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Through a vulnerability in one service on a server, the attacker gains access to other services running on the same server.",
    "Measure": "Applications are running in a dedicated and isolated virtualized environments.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Virtual environments are not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Filter outgoing traffic",
    "Level": "3",
    "Description": "Filtering outgoing traffic involves implementing network controls to restrict and monitor the data leaving the organization's network. This enhances security by preventing unauthorized data exfiltration and reducing the risk of malware communication. Pipeline-compatible tools like AWS Network Firewall, Azure Firewall, and Cisco ASA can automate the configuration and management of outbound traffic filters within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "AWS Network Firewall",
        "Description": "Managed service that provides essential network protections to filter outgoing traffic within AWS environments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Firewall",
        "Description": "Managed, cloud-based network security service that protects Azure Virtual Network resources by filtering outgoing traffic.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Cisco ASA",
        "Description": "Adaptive Security Appliance that provides advanced firewall capabilities to filter outgoing traffic and enhance network security.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "A compromised infrastructure component might try to send out stolen data.",
    "Measure": "Having a whitelist and explicitly allowing egress traffic provides the ability to stop unauthorized data leakage.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "Medium",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Virtual environments are not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Isolated networks for virtual environments",
    "Level": "2",
    "Description": "Implementing isolated networks for virtual environments involves segmenting network traffic to ensure that different virtual environments do not interfere with each other. This enhances security by preventing unauthorized access and limiting the spread of potential threats across environments. Pipeline-compatible tools like AWS VPC, Azure Virtual Network, and VMware NSX can automate the creation and management of isolated networks within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "AWS VPC",
        "Description": "Virtual Private Cloud service that allows the creation of isolated networks within AWS environments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Virtual Network",
        "Description": "Service that enables the creation of isolated networks within Azure, providing secure communication channels.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "VMware NSX",
        "Description": "Network virtualization platform that provides advanced network isolation and security features for virtual environments.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Virtual environments in default settings are able to access other virtual environments on the network stack. By using virtual machines, it is often possible to connect to other virtual machines. By using docker, one bridge is used by default so that all containers on one host can communicate with each other.",
    "Measure": "The communication between virtual environments is controlled and regulated.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Virtual environments are not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Virtual environments are limited",
    "Level": "2",
    "Description": "Limiting virtual environments involves restricting the use of virtualized resources to enhance security and control over the infrastructure. This ensures that only authorized and necessary virtual environments are deployed, reducing the attack surface. Tools like Terraform and Ansible can manage and enforce policies for virtual environment deployments within DevSecOps pipelines.",
    "Tools": [
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code (IaC) tool that allows for the creation, management, and enforcement of virtual environment configurations.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "Automation tool used for configuration management and enforcing infrastructure policies, including virtual environment restrictions.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Denial of service (internally by an attacker or unintentionally by a bug) on one service effects other services",
    "Measure": "All virtual environments are using resource limits on hard disks, memory and CPU",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "High",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "Virtual environments are not explicitly covered by ISO 27001 - too specific,8.6,8.22,8.14"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test the definition of virtualized environments",
    "Level": "2",
    "Description": "Testing the definition of virtualized environments involves validating the configurations and settings of virtual environments to ensure they meet security and performance standards. This includes verifying virtualization settings, network configurations, and resource allocations. Tools like Terraform, Ansible, and Packer can be integrated into DevSecOps pipelines to automate the testing and validation of virtual environment definitions.",
    "Tools": [
      {
        "Name": "Terraform",
        "Description": "Allows for the definition and validation of virtualized environments through Infrastructure as Code (IaC), integrating with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "Automates the configuration and validation of virtual environments, compatible with CI/CD workflows for continuous testing.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Packer",
        "Description": "Automates the creation and testing of machine images for virtual environments, integrating with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "The definition of virtualized environments (e.g. via <i>Dockerfile</i>) might contain unsecure configurations.",
    "Measure": "Test the definition of virtualized environments for unsecured configurations.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "System hardening, virtual environments are not explicitly covered by ISO 27001 - too specific,8.8,8.32,8.29,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Limitation of system events",
    "Level": "3",
    "Description": "Limiting system events involves restricting the types and frequency of system logs and events to essential information. This helps in reducing noise, improving log management efficiency, and focusing on critical security-related events. Tools such as Syslog-ng, Logstash, Splunk, Graylog, ELK Stack, Fluentd, and Nagios can be utilized to manage and filter system events effectively.",
    "Tools": [
      {
        "Name": "Syslog-ng",
        "description": "Enhanced version of the syslog protocol with advanced filtering and processing capabilities.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Logstash",
        "description": "Data processing pipeline that ingests, transforms, and forwards logs.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Splunk",
        "description": "Platform for searching, monitoring, and analyzing machine-generated data, with capabilities to filter system events.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Graylog",
        "description": "Open-source log management platform with event filtering capabilities.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "description": "Comprehensive logging solution with event filtering and visualization.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Fluentd",
        "description": "Open-source data collector for unified logging.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Nagios",
        "description": "Monitoring tool that can be configured to limit and filter system events.",
        "opensource": true,
        "languages": []
      }
    ],
    "Risk": "System events (system calls) can lead to privilege escalation.",
    "Measure": "System calls are limited.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "System hardening is not explicitly covered by ISO 27001 - too specific",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Test of the configuration of cloud environments",
    "Level": "2",
    "Description": "Testing the configuration of cloud environments involves verifying that cloud resources are correctly configured according to security and performance standards. This ensures that cloud deployments are secure, efficient, and compliant with organizational policies. Tools like AWS Config, Azure Resource Manager, and Google Cloud Config Connector can be integrated into DevSecOps pipelines to automate the testing and validation of cloud environment configurations.",
    "Tools": [
      {
        "Name": "AWS Config",
        "Description": "Monitors and evaluates the configurations of AWS resources, ensuring compliance and security within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Resource Manager",
        "Description": "Manages and validates Azure resource configurations, integrated with CI/CD workflows for automated configuration testing.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Google Cloud Config Connector",
        "Description": "Enables the management and validation of Google Cloud resource configurations through Infrastructure as Code, compatible with DevSecOps pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Standard hardening practices for cloud environments are not performed leading to vulnerabilities.",
    "Measure": "With the help of tools the configuration of virtual environments are tested.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "System hardening is not explicitly covered by ISO 27001 - too specific,8.8,8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test cluster deployment resources",
    "Level": "2",
    "Description": "Testing cluster deployment resources involves verifying that the resources allocated for cluster deployments are adequate and configured correctly to support application scalability and performance. This ensures that deployments are efficient and resources are optimally utilized. Tools like Terraform, Kubernetes, and Helm can be integrated into DevSecOps pipelines to automate the testing and validation of cluster deployment configurations.",
    "Tools": [
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code (IaC) tool that allows for the creation, management, and validation of cluster deployment configurations within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "An open-source container orchestration platform that manages cluster deployments and can be integrated with CI/CD pipelines for automated testing.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Helm",
        "Description": "A package manager for Kubernetes that simplifies the deployment and management of applications within clusters, compatible with CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "The deployment configuration (e.g. kubernetes deployment resources) might contain unsecured configurations.",
    "Measure": "Test the deployment configuration for virtualized environments for unsecured configurations.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "System hardening is not explicitly covered by ISO 27001 - too specific,8.8,8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test the cloud configuration",
    "Level": "2",
    "Description": "Testing the cloud configuration involves verifying that cloud resources are correctly configured according to security and performance standards. This ensures that cloud deployments are secure, efficient, and compliant with organizational policies. Tools like AWS Config, Azure Resource Manager, and Google Cloud Config Connector can be integrated into DevSecOps pipelines to automate the testing and validation of cloud environment configurations.",
    "Tools": [
      {
        "Name": "AWS Config",
        "Description": "Monitors and evaluates the configurations of AWS resources, ensuring compliance and security within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Resource Manager",
        "Description": "Manages and validates Azure resource configurations, integrated with CI/CD workflows for automated configuration testing.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Google Cloud Config Connector",
        "Description": "Enables the management and validation of Google Cloud resource configurations through Infrastructure as Code, compatible with DevSecOps pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Standard hardening practices for cloud environments are not performed leading to vulnerabilities.",
    "Measure": "With the help of tools, the configuration of virtual environments are tested.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "System hardening is not explicitly covered by ISO 27001 - too specific,8.8,8.32,8.29"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Each team has a security champion",
    "Level": "2",
    "Description": "Assigning a security champion to each team involves designating a team member responsible for advocating and integrating security best practices within their respective teams. This fosters a security-first mindset and ensures continuous security oversight. Pipeline-compatible tools like Confluence and Jira can support the role of security champions by providing documentation and tracking capabilities.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Project management tool that can track security tasks and responsibilities assigned to security champions.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Confluence",
        "Description": "Collaboration tool for documenting security best practices and guidelines accessible to security champions.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "No one feels directly responsible for security and the security champion does not have enough time to allocate to each team.",
    "Measure": "Each team defines an individual to be responsible for security. These individuals are often referred to as 'security champions'",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "G-EG-1-B,G-EG-2-B",
    "ISO 27001:2017": "7.2.1",
    "ISO 27001:2022": "Security champions are missing in ISO 27001 most likely,5.4,6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Regular security training of security champions",
    "Level": "2",
    "Description": "Providing regular security training to security champions ensures they are well-equipped with the latest security knowledge and best practices. This enables them to effectively guide their teams and address emerging security challenges. Pipeline-compatible tools like Learning Management Systems (LMS) such as Moodle or Coursera can facilitate ongoing training and certification for security champions.",
    "Tools": [],
    "Risk": "Understanding security is hard, even for security champions.",
    "Measure": "Regular security training of security champions.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "",
    "SAMM": "D-TA-2-B,G-EG-1-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "Security champions are missing in ISO 27001,6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Process",
    "Activity": "Approval by reviewing any new version",
    "Level": "3",
    "Description": "Implementing an approval process by reviewing any new version involves mandating security and quality checks before deploying new software versions. This ensures that each release meets the organization's security standards and reduces the risk of introducing vulnerabilities. Pipeline-compatible tools like GitHub Actions, GitLab CI/CD, and Jenkins can automate the approval and review process within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "GitHub Actions",
        "Description": "CI/CD tool that can automate the approval and review process for new software versions.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Integrated CI/CD tool that can enforce approval workflows and security checks before deploying new versions.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate approval and review processes for new software versions within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "An individual might forget to implement security measures to protect source code or infrastructure components.",
    "Measure": "On each new version (e.g. Pull Request) of source code or infrastructure components a security peer review of the changes is performed (two eyes principle) and approval given by the reviewer.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Peer review - four eyes principle is not explicitly required by ISO 27001,5.3,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Dismiss stale PR approvals",
    "Level": "3",
    "Description": "Dismissing stale Pull Request (PR) approvals involves automatically revoking approvals that are no longer valid due to subsequent changes in the codebase. This ensures that PRs are re-reviewed to maintain code quality and security standards. Pipeline-compatible tools like GitHub Actions, GitLab CI/CD, and Jenkins can automate the dismissal of stale PR approvals within CI/CD workflows.",
    "Tools": [
      {
        "Name": "GitHub Actions",
        "Description": "CI/CD tool that can automate the dismissal of stale PR approvals based on predefined criteria.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Integrated CI/CD tool that can manage and automate the dismissal of stale PR approvals.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate the dismissal of stale PR approvals within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Intentional or accidental alterations in critical branches like main (or master) through post-approval code additions.",
    "Measure": "Implement a policy where any commits made after a pull request has been approved automatically revoke that approval, necessitating a fresh review and re-approval process.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Peer review - four eyes principle is not explicitly required by ISO 27001,5.3,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Require a PR before merging",
    "Level": "2",
    "Description": "Requiring a Pull Request (PR) before merging ensures that all code changes are reviewed and approved by peers, maintaining code quality and security standards. Pipeline-compatible tools like GitHub, GitLab, and Bitbucket can enforce PR requirements and integrate automated checks within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "GitHub",
        "Description": "Version control platform that can enforce PR requirements and integrate automated checks within CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab",
        "Description": "Integrated version control and CI/CD tool that can mandate PRs and automate review processes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Bitbucket",
        "Description": "Version control platform that can enforce PR requirements and integrate automated security checks within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Intentional or accidental alterations in critical branches like main (or master).",
    "Measure": "Define source code management system policies (e.g. branch protection rules, mandatory code reviews from at least one person, ...) to ensure that changes to critical branches are only possible under defined conditions. These policies can be implemented at repository level or organization level, depending on the source code management system.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Peer review - four eyes principle is not explicitly required by ISO 27001,5.3,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": ".gitignore",
    "Level": "4",
    "Description": "Configuring a .gitignore file involves specifying files and directories that should be excluded from version control to prevent sensitive information, build artifacts, and unnecessary files from being tracked. Pipeline-compatible tools like GitHub, GitLab, and Bitbucket can utilize .gitignore configurations to streamline version control processes within CI/CD pipelines.",
    "Tools": [],
    "Risk": "Unintended leakage of secrets, debug, or workstation specific data",
    "Measure": ".gitignore files help prevent accidental commits of secrets, debug, or workstation specific data",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "12.1.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.37,8.32"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Versioning",
    "Level": "1",
    "Description": "Implementing versioning involves managing changes to the source code over time, enabling tracking, collaboration, and rollback capabilities. Proper versioning ensures that all code changes are documented and that teams can collaborate effectively. Pipeline-compatible tools like Git, GitHub, GitLab, and Bitbucket can automate version control processes within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Git",
        "Description": "Distributed version control system for tracking changes in source code during software development.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitHub",
        "Description": "Web-based platform that uses Git for version control and offers collaboration features like pull requests and issue tracking.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab",
        "Description": "Integrated DevOps platform that provides Git repository management, CI/CD pipelines, and version control.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Bitbucket",
        "Description": "Git repository management solution designed for professional teams, offering features like pull requests and branch permissions.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Deployment of untracked artifacts.",
    "Measure": "Version artifacts in order to identify deployed features and issues. This includes application and infrastructure code, jenkins configuration, container and virtual machine images.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "12.1.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.37,8.32"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Immutable infrastructure",
    "Level": "3",
    "Description": "Implementing immutable infrastructure involves designing systems where components are never modified after deployment. Instead, any updates or changes result in new deployments. This approach enhances security by reducing the attack surface and ensuring consistency across environments. Pipeline-compatible tools like Terraform, Kubernetes, and Docker can automate the deployment of immutable infrastructure within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code tool that automates the provisioning of immutable infrastructure by managing infrastructure changes incrementally.",
        "Opensource": true,
        "Languages": ["HCL"]
      },
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that manages immutable deployments by deploying and scaling containerized applications without modifying existing instances.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Docker",
        "Description": "Platform for developing, shipping, and running applications in containers, supporting the creation of immutable infrastructure.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "The availability of IT systems might be disturbed due to components failures",
    "Measure": "Redundancies in the IT systems",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "17.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.14"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Infrastructure as Code",
    "Level": "3",
    "Description": "Infrastructure as Code (IaC) involves managing and provisioning computing infrastructure through machine-readable configuration files rather than manual processes. This practice ensures consistency, repeatability, and version control of infrastructure deployments, enhancing security and efficiency. Tools like Terraform, Ansible, Puppet, Chef, CloudFormation, Azure Resource Manager (ARM) Templates, Pulumi, SaltStack, and Google Cloud Deployment Manager support IaC implementations.",
    "Tools": [
      {
        "Name": "Terraform",
        "description": "Open-source IaC tool for building, changing, and versioning infrastructure safely and efficiently.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Ansible",
        "description": "Automation tool for configuring and managing infrastructure as code.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Puppet",
        "description": "Configuration management tool that supports IaC for automating infrastructure provisioning.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Chef",
        "description": "Automation platform that transforms infrastructure into code.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "CloudFormation",
        "description": "AWS service for modeling and setting up AWS resources using templates.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Azure Resource Manager (ARM) Templates",
        "description": "Defines Azure infrastructure and services using JSON templates.",
        "opensource": false,
        "languages": []
      },
      {
        "Name": "Pulumi",
        "description": "Infrastructure as Code tool that allows defining cloud resources using programming languages.",
        "opensource": false,
        "languages": ["JavaScript", "TypeScript", "Python", "Go", "C#"]
      },
      {
        "Name": "SaltStack",
        "description": "Configuration management and orchestration tool supporting IaC practices.",
        "opensource": true,
        "languages": []
      },
      {
        "Name": "Google Cloud Deployment Manager",
        "description": "Service for defining and deploying Google Cloud infrastructure using configuration files.",
        "opensource": false,
        "languages": []
      }
    ],
    "Risk": "No tracking of changes in systems might lead to errors in the configuration. In additions, it might lead to unauthorized changes. An examples is jenkins.",
    "Measure": "Systems are setup by code. A full environment can be provisioned. In addition, software like Jenkins 2 can be setup and configured in in code too. The code should be stored in a version control system.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Very High",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "12.1.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.37,8.32"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of a chaos monkey",
    "Level": "4",
    "Description": "Using a chaos monkey involves intentionally introducing failures into the system to test its resilience and fault tolerance. This practice helps identify weaknesses and ensures that the infrastructure can withstand unexpected disruptions. Pipeline-compatible tools like Gremlin, Chaos Toolkit, and AWS Fault Injection Simulator can automate chaos engineering experiments within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Gremlin",
        "Description": "Chaos engineering tool that safely introduces failures to test system resilience and fault tolerance.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Chaos Toolkit",
        "Description": "Open-source tool for running chaos experiments to improve system reliability and resilience.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Fault Injection Simulator",
        "Description": "Managed service that enables running chaos engineering experiments on AWS infrastructure.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Due to manual changes on a system, they are not replaceable anymore. In case of a crash it might happen that a planned redundant system is unavailable. In addition, it is hard to replay manual changes.",
    "Measure": "A randomized periodically shutdown of systems makes sure, that nobody will perform manual changes to a system.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "17.1.3",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.29"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "Centralized application logging",
    "Level": "3",
    "Description": "Centralized application logging involves aggregating logs from various applications into a single, centralized system. This facilitates easier monitoring, troubleshooting, and analysis of application behavior and security events. Tools like ELK Stack (Elasticsearch, Logstash, Kibana), Splunk, and Fluentd can be integrated into DevSecOps pipelines to automate the collection and centralization of application logs.",
    "Tools": [
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "Description": "A powerful set of tools (Elasticsearch, Logstash, Kibana) for centralized logging, visualization, and analysis, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "A comprehensive platform for searching, monitoring, and analyzing machine-generated data, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Fluentd",
        "Description": "An open-source data collector for unified logging layers, integrated into CI/CD pipelines for centralized log management.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Local stored logs can be unauthorized manipulated by attackers with system access or might be corrupt after an incident. In addition, it is hard to perform an correlation of logs. This leads attacks, which can be performed silently.",
    "Measure": "A centralized logging system is used and applications logs (including application exceptions) are shipped to it.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.15"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "Centralized system logging",
    "Level": "1",
    "Description": "Centralized system logging involves aggregating logs from various system components into a single, centralized repository. This enables efficient monitoring, analysis, and troubleshooting of system-level events and issues. Tools like Syslog, Graylog, and Splunk can be integrated into DevSecOps pipelines to automate the collection and centralization of system logs.",
    "Tools": [
      {
        "Name": "Syslog",
        "Description": "A standard protocol for message logging that aggregates system logs into a centralized server, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Graylog",
        "Description": "An open-source log management platform that centralizes and analyzes system logs, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "A comprehensive platform for searching, monitoring, and analyzing machine-generated data, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Local stored system logs can be unauthorized manipulated by attackers or might be corrupt after an incident. In addition, it is hard to perform a aggregation of logs.",
    "Measure": "By using centralized logging logs are protected against unauthorized modification.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.15"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "Correlation of security events",
    "Level": "5",
    "Description": "Correlation of security events involves analyzing and linking disparate security events from various sources to identify patterns, detect threats, and respond to incidents effectively. This enhances the ability to detect complex attacks and improve overall security posture. Tools like Splunk, IBM QRadar, and ArcSight can be integrated into DevSecOps pipelines to automate the correlation and analysis of security events.",
    "Tools": [
      {
        "Name": "Splunk",
        "Description": "A comprehensive platform for searching, monitoring, and analyzing machine-generated data, enabling correlation of security events within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "IBM QRadar",
        "Description": "A security information and event management (SIEM) solution that correlates security events for threat detection and response, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "ArcSight",
        "Description": "Provides advanced SIEM capabilities for correlating and analyzing security events, integrated into CI/CD pipelines for continuous security monitoring.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Detection of security related events with hints on different systems/tools/metrics is not possible.",
    "Measure": "Events are correlated on one system. For example the correlation and visualization of failed login attempts combined with successful login attempts.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Very High",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.15"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "PII logging concept",
    "Level": "5",
    "Description": "PII logging concept involves establishing guidelines and mechanisms for securely logging Personally Identifiable Information (PII) to ensure compliance with data protection regulations and prevent unauthorized access. This includes implementing data masking, encryption, and access controls for logs containing PII. Tools like Splunk, Logstash, and Fluentd can be configured within DevSecOps pipelines to enforce PII protection measures during logging.",
    "Tools": [
      {
        "Name": "Splunk",
        "Description": "Provides secure logging capabilities with support for data masking and encryption, ensuring PII protection within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Logstash",
        "Description": "A data processing pipeline that can be configured to mask and encrypt PII in logs, integrated into CI/CD workflows for secure logging.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fluentd",
        "Description": "An open-source data collector that can enforce PII protection measures through data transformation and encryption within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Personal identifiable information (PII) is logged and the privacy law (e.g. General Data Protection Regulation) is not followed.",
    "Measure": "A concept how to log PII is documented and applied.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.15,5.31"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "Visualized logging",
    "Level": "2",
    "Description": "Visualized logging involves presenting log data in a visual format, such as dashboards and graphs, to facilitate easier monitoring, analysis, and identification of trends or anomalies. This enhances the ability to quickly interpret and respond to log data. Tools like Kibana, Grafana, and Splunk can be integrated into DevSecOps pipelines to provide visual representations of log data.",
    "Tools": [
      {
        "Name": "Kibana",
        "Description": "A visualization tool for Elasticsearch that creates interactive dashboards and graphs from log data, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "An open-source platform for monitoring and observability that visualizes log and metric data, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "A comprehensive platform for searching, monitoring, and analyzing machine-generated data with built-in visualization capabilities, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "System and application protocols are not visualized properly which leads to no or very limited logging assessment. Specially developers might have difficulty to read applications logs with unusually tools like the Linux tool 'cat'",
    "Measure": "Protocols are visualized in a simple to use real time monitoring system. The GUI gives the ability to search for special attributes in the protocol.",
    "Knowledge": "Low (one discipline)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.15"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Deactivation of unused metrics",
    "Level": "3",
    "Description": "Deactivation of unused metrics involves identifying and disabling metrics that are no longer relevant or necessary. This optimization reduces resource consumption and focuses monitoring efforts on critical metrics. Tools like Prometheus, Grafana, and Datadog can be configured within DevSecOps pipelines to automate the identification and deactivation of unused metrics.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that can be configured to deactivate unused metrics within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that can be used to manage and deactivate unused metrics within DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "A monitoring and analytics platform that allows for the deactivation of unused metrics to optimize resource usage within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "High resources are used while gathering unused metrics.",
    "Measure": "Deactivation of unused metrics helps to free resources.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "",
    "Time": "",
    "Usefulness": "",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Grouping of metrics",
    "Level": "3",
    "Description": "Grouping of metrics involves categorizing related metrics together to enhance clarity and facilitate more effective monitoring and analysis. This organization helps in identifying trends and correlations within different metric groups. Tools like Grafana, Prometheus, and Datadog can be integrated into DevSecOps pipelines to automate the grouping and visualization of related metrics.",
    "Tools": [
      {
        "Name": "Grafana",
        "Description": "A visualization tool that allows for the grouping and organization of related metrics into dashboards, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that supports the grouping of related metrics for organized monitoring within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "A monitoring and analytics platform that enables the grouping of related metrics for better organization and analysis within DevSecOps pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "The analysis of metrics takes long.",
    "Measure": "Meaningful grouping of metrics helps to speed up analysis.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "Medium",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Screens with metric visualization",
    "Level": "4",
    "Description": "Creating screens with metric visualization involves designing and implementing dashboards that display key performance and security metrics. This provides real-time insights into system performance and security posture, enabling timely decision-making and response. Pipeline-compatible tools like Grafana, Kibana, and Datadog can automate the creation and updating of metric visualization dashboards within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Grafana",
        "Description": "Open-source platform for creating detailed dashboards that visualize performance and security metrics from various data sources.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kibana",
        "Description": "Visualization tool for the ELK Stack that creates interactive dashboards for monitoring metrics and logs.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "Monitoring and analytics platform that provides customizable dashboards for visualizing key metrics.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Security related information is discovered too late during an incident.",
    "Measure": "By having an internal accessible screen with a security related dashboards helps to visualize incidents.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "16.1.5",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.26"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Targeted alerting",
    "Level": "3",
    "Description": "Implementing targeted alerting involves setting up specific alerts for critical events or thresholds to ensure prompt responses to significant issues. This enhances security and operational efficiency by focusing attention on high-impact events. Pipeline-compatible tools like PagerDuty, Opsgenie, and Datadog can automate targeted alerting within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "PagerDuty",
        "Description": "Incident response platform that manages and routes alerts for prompt issue resolution.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Opsgenie",
        "Description": "Alerting and incident management tool that ensures critical alerts are promptly addressed.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "Monitoring and analytics platform that provides customizable alerting based on specific metrics and events.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "People are bored (ignorant) of incident alarm messages, as they are not responsible to react.",
    "Measure": "By the definition of target groups for incidents people are only getting alarms for incidents they are in charge for.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "",
    "Time": "",
    "Usefulness": "",
    "SAMM": "I-DM-A 3",
    "ISO 27001:2017": "16.1.5",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.26"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Integration of vulnerability issues into the development process",
    "Level": "3",
    "Description": "Integrating vulnerability issues into the development process involves embedding security checks and vulnerability assessments into the software development lifecycle (SDLC). This ensures that vulnerabilities are identified and addressed early, promoting a proactive approach to security. Pipeline-compatible tools like SonarQube, GitLab CI/CD, and Snyk can be integrated to automate vulnerability tracking and remediation.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that identifies vulnerabilities and integrates with development pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Continuous integration and delivery tool integrated with GitLab repositories for managing vulnerability tracking.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that finds and fixes vulnerabilities in dependencies and container images.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "To read console output of the build server to search for vulnerabilities might be difficult. Also, to check a vulnerability management system might not be a daily task for a developer.",
    "Measure": "Vulnerabilities are tracked in the teams issue system (e.g. jira).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.25,5.26,5.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Simple false positive treatment",
    "Level": "1",
    "Description": "Simple false positive treatment involves identifying and dismissing alerts or findings that are incorrectly flagged as vulnerabilities. This helps in reducing noise and focusing on genuine security issues. Pipeline-compatible tools like SonarQube and GitLab SAST can automate the dismissal of false positives within CI/CD workflows.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that allows for marking certain alerts as false positives to reduce noise.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab SAST",
        "Description": "Static Application Security Testing integrated within GitLab for scanning code and managing false positives.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitHub Advanced Security",
        "Description": "Provides features to mark certain security alerts as false positives within GitHub repositories.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "ESLint",
        "Description": "Linting tool for JavaScript that can be configured to ignore certain warnings or errors.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "PyLint",
        "Description": "Static code analysis tool for Python that detects security vulnerabilities and code quality issues.",
        "Opensource": true,
        "Languages": ["Python"]
      },
      {
        "Name": "IDE Plugins (e.g., PyCharm, VSCode)",
        "Description": "Integrated development environment plugins that allow developers to mark specific findings as false positives.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "As false positive occur during each test, all vulnerabilities might be ignored.",
    "Measure": "False positives are suppressed so they will not show up on the next tests again. Most security tools have the possibility to suppress false positives. A Vulnerability Management System might be used.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "I-DM-2-A",
    "ISO 27001:2017": "16.1.6",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,5.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Dead code elimination",
    "Level": "5",
    "Description": "Dead code elimination involves identifying and removing unused or redundant code from the codebase to improve maintainability, reduce potential vulnerabilities, and optimize performance. This process can be integrated into DevSecOps pipelines using static analysis tools that automatically detect and flag dead code during the CI/CD process. Tools like SonarQube, ESLint, and PMD support automated dead code detection and elimination.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "A static analysis tool that detects dead code and other code quality issues, integrating seamlessly with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "ESLint",
        "Description": "A static code analysis tool for identifying and eliminating dead code in JavaScript projects, easily integrated into CI/CD workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "PMD",
        "Description": "A source code analyzer that identifies dead code and other potential issues in Java and other languages, compatible with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Dead code increases the attack surface (use of hard coded credentials and variables, sensitive information)",
    "Measure": "Collection of unused code and then manual removal of unused code.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Exclusion of source code duplicates",
    "Level": "5",
    "Description": "Excluding source code duplicates involves identifying and removing duplicate code segments to enhance code quality, maintainability, and security. This practice reduces the risk of inconsistencies and vulnerabilities across the codebase. Tools like SonarQube, PMD, and CodeClimate can be integrated into DevSecOps pipelines to automate the detection and exclusion of duplicate code during the CI/CD process.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Detects duplicate code and other code quality issues, integrating with CI/CD pipelines for automated monitoring.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "PMD",
        "Description": "Analyzes source code to identify duplicates and other issues, compatible with various CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "CodeClimate",
        "Description": "Provides duplicate code detection and quality metrics, seamlessly integrating into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Duplicates in source code might influence the stability of the application.",
    "Measure": "Automatic Detection and manual removal of duplicates in source code.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Test for Patch Deployment Time",
    "Level": "3",
    "Description": "Testing for patch deployment time involves measuring and optimizing the duration required to deploy security patches to applications. This ensures timely updates and minimizes the window of vulnerability. Tools like Jenkins, GitLab CI/CD, and Ansible can automate patch deployment processes, allowing for continuous monitoring and optimization of deployment times within DevSecOps pipelines.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Automates patch deployment processes and measures deployment times within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Facilitates automated patch deployments and provides metrics on deployment times as part of the CI/CD process.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "Automates patch deployment tasks and integrates with CI/CD pipelines to monitor and optimize deployment times.",
        "Opensource": true,
        "Languages": ["YAML"]
      }
    ],
    "Risk": "Automatic PRs for dependencies are overlooked resulting in known vulnerabilities in production artifacts.",
    "Measure": "Test of the Patch Deployment Time. This activity is not repeated in the Sub-Dimension \"\"Static depth for infrastructure\"\", but it applies to infrastructure as well.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Test for Time to Patch",
    "Level": "2",
    "Description": "Testing for time to patch involves evaluating the efficiency and speed at which patches are applied to address vulnerabilities. This ensures that critical updates are deployed promptly to mitigate security risks. Tools like Jenkins, GitLab CI/CD, and Puppet can be integrated into DevSecOps pipelines to automate and monitor patch deployment processes, enabling faster response times to identified vulnerabilities.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Automates the patch deployment process and tracks the time taken to apply patches within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Enables automated patch deployments and provides tracking for patch deployment times as part of the CI/CD workflow.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Puppet",
        "Description": "Automates configuration management and patch deployments, integrating with CI/CD pipelines to monitor deployment times.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Automatic PRs for dependencies are overlooked resulting in known vulnerabilities in production artifacts.",
    "Measure": "Test of the Time to Patch (e.g. based on Mean Time to Close automatic PRs) This activity is not repeated in the Sub-Dimension \"\"Static depth for infrastructure\"\", but it applies to infrastructure as well.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Test libyear",
    "Level": "2",
    "Description": "Testing libyear involves assessing the usage and maintenance of third-party libraries and dependencies to ensure they are up-to-date and free from known vulnerabilities. This practice helps in maintaining the security and stability of applications. Tools like Snyk, Dependabot, and Renovate can be integrated into DevSecOps pipelines to automate the monitoring and updating of library dependencies.",
    "Tools": [
      {
        "Name": "Snyk",
        "Description": "Monitors and scans dependencies for vulnerabilities, integrating with CI/CD pipelines to ensure libraries are up-to-date and secure.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Dependabot",
        "Description": "Automatically creates pull requests to update dependencies and fix vulnerabilities, seamlessly integrating with CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Renovate",
        "Description": "Automates dependency updates and integrates with CI/CD pipelines to manage and secure library dependencies.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities in running artifacts stay for long and might get exploited.",
    "Measure": "Test `libyear`, which provides a good insight how good patch management is.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Conduction of simple threat modeling on technical level",
    "Level": "1",
    "Description": "Conducting simple threat modeling on a technical level involves identifying potential security threats and vulnerabilities in the system's architecture and design. This helps in proactively addressing security concerns during the design phase. While pipeline-compatible tools for threat modeling are limited, methodologies like STRIDE and tools such as Microsoft Threat Modeling Tool can be utilized to standardize threat identification processes.",
    "Tools": [],
    "Risk": "Technical related threats are discovered too late in the development and deployment process.",
    "Measure": "Threat modeling of technical features is performed during the product sprint planning.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "D-TA-2-B",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001,May be part of risk assessment,5.12,8.25"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Creation of advanced abuse stories",
    "Level": "5",
    "Description": "Creating advanced abuse stories involves developing detailed and complex scenarios where malicious actors attempt to exploit system vulnerabilities. These stories help in understanding potential attack vectors, enhancing security measures, and improving incident response strategies. While not directly pipeline-compatible, frameworks like MITRE ATT&CK can inform the creation of these abuse stories.",
    "Tools": [],
    "Risk": "Simple user stories are not going deep enough. Relevant security considerations are performed. Security flaws are discovered too late in the development and deployment process",
    "Measure": "Advanced abuse stories are created as part of threat modeling activities.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "D-TA-2-B",
    "ISO 27001:2017": "5/31/2005",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001,May be part of project management,5.8,May be part of risk assessment,5.9"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Creation of simple abuse stories",
    "Level": "3",
    "Description": "Creating simple abuse stories involves developing basic scenarios where attackers exploit common vulnerabilities. These stories assist in identifying fundamental security gaps and informing the development of effective security controls. Tools like OWASP Threat Dragon can aid in visualizing these scenarios within development workflows.",
    "Tools": [],
    "Risk": "User stories mostly don't consider security implications. Security flaws are discovered too late in the development and deployment process.",
    "Measure": "Abuse stories are created during the creation of user stories.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "D-TA-2-B",
    "ISO 27001:2017": "5/31/2005",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001,May be part of project management,5.8,May be part of risk assessment,5.9"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Creation of threat modeling processes and standards",
    "Level": "3",
    "Description": "Creating threat modeling processes and standards involves establishing structured methodologies and guidelines for identifying, assessing, and mitigating security threats during the system design and development phases. This ensures consistency and thoroughness in threat modeling efforts across the organization. Pipeline-compatible tools like Microsoft Threat Modeling Tool can be integrated to standardize threat modeling within development pipelines.",
    "Tools": [
      {
        "Name": "Microsoft Threat Modeling Tool",
        "Description": "Tool for creating and managing threat models to identify and mitigate security risks.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Inadequate identification of business and technical risks.",
    "Measure": "Creation of threat modeling processes and standards through the organization helps to enhance the security culture and provide more structure to the threat model exercises.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "D-TA-3-B",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001,May be part of risk assessment,5.12,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Microservice-architecture",
    "Level": "5",
    "Description": "Adopting a microservice architecture involves structuring an application as a collection of loosely coupled, independently deployable services. This approach enhances scalability, flexibility, and resilience, but also introduces new security considerations such as inter-service communication, service discovery, and container security. Pipeline-compatible tools like Kubernetes, Docker, Istio, and Helm can automate the deployment and management of microservices within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that manages the deployment, scaling, and operations of application containers.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Docker",
        "Description": "Platform for developing, shipping, and running applications in containers, essential for microservice deployments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Istio",
        "Description": "Service mesh that provides a uniform way to secure, connect, and observe microservices.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Linkerd",
        "Description": "Lightweight service mesh for Kubernetes, focusing on simplicity and performance.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Consul",
        "Description": "Service networking solution that provides service discovery, configuration, and segmentation.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Envoy",
        "Description": "High-performance proxy designed for cloud-native applications, used in service meshes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Helm",
        "Description": "Package manager for Kubernetes that simplifies the deployment and management of microservices.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Monolithic applications are hard to test.",
    "Measure": "A microservice-architecture helps to have small components, which are more easy to test.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "",
    "Time": "",
    "Usefulness": "Low",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "Not explicitly covered by ISO 27001",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Conduction of collaborative team security checks",
    "Level": "4",
    "Description": "Conducting collaborative team security checks involves teams working together to review and assess the security posture of their applications and infrastructure. This collaborative approach fosters a shared responsibility for security, enhances knowledge sharing, and ensures that diverse perspectives are considered in identifying and mitigating security risks. While not directly pipeline-compatible, tools like Jira and Confluence can facilitate collaboration and tracking of security checks.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Project management tool that can track and manage collaborative security check tasks.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Confluence",
        "Description": "Collaboration tool for documenting and sharing security check findings and strategies.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Development teams limited insight over security practices.",
    "Measure": "Mutual security testing the security of other teams project enhances security awareness and knowledge.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "Medium",
    "SAMM": "G-EG-1-A,G-EG-2-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "Mutual security testing is not explicitly required in ISO 27001 may be,6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Conduction of collaborative security checks with developers and system administrators",
    "Level": "5",
    "Description": "Conducting collaborative security checks with developers and system administrators involves joint efforts to evaluate and enhance the security measures of applications and infrastructure. This collaboration ensures that both development and operations teams are aligned on security best practices, facilitates the identification of vulnerabilities, and promotes a culture of continuous security improvement. Pipeline-compatible tools like GitLab CI/CD and Jenkins can integrate security checks into collaborative workflows.",
    "Tools": [
      {
        "Name": "GitLab CI/CD",
        "Description": "Continuous integration and delivery tool that can integrate security checks into collaborative development workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate collaborative security check pipelines involving multiple teams.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Security checks by external companies do not increase the understanding of an application/system for internal employees.",
    "Measure": "Periodically security reviews of source code (SCA), in which security SME, developers and operations are involved, are effective at increasing the robustness of software and the security knowledge of the teams involved.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "G-EG-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "Mutual review of source code is not explicitly required in ISO 27001 may be,6.3,8.8,8.34"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Security code review",
    "Level": "2",
    "Description": "Conducting security code reviews involves systematically examining source code to identify and remediate security vulnerabilities. This practice ensures that code adheres to security best practices and reduces the risk of introducing vulnerabilities into the application. Pipeline-compatible tools like SonarQube, GitHub CodeQL, and GitLab SAST can automate security code reviews within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for security vulnerabilities and code quality issues.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitHub CodeQL",
        "Description": "Semantic code analysis engine for identifying vulnerabilities in codebases hosted on GitHub.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab SAST",
        "Description": "Static Application Security Testing integrated within GitLab for scanning code for vulnerabilities.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Checkmarx",
        "Description": "Static Application Security Testing (SAST) tool that scans code for security vulnerabilities.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Comprehensive application security testing tool that identifies vulnerabilities in source code.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that finds and fixes vulnerabilities in dependencies and container images.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "ESLint",
        "Description": "Linting tool for JavaScript that can be configured with security-focused rules.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      }
    ],
    "Risk": "Understanding security is hard.",
    "Measure": "The following areas of code tend to have a high-risk of containing security vulnerabilities: - Crypto implementations / usage - Parser, unparser - System configuration - Authentication, authorization - Session management - Request throttling - :unicorn: (self-developed code, only used in that one software)",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-1-B",
    "ISO 27001:2017": "ISO 27001:2017 mapping is missing",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Analyze logs",
    "Level": "3",
    "Description": "Analyzing logs involves examining system and application log data to identify patterns, detect anomalies, and uncover potential security incidents. This practice is crucial for incident detection, troubleshooting, and ensuring compliance with security policies. Pipeline-compatible tools like ELK Stack, Splunk, and Graylog can automate log analysis within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "Description": "Comprehensive logging and monitoring solution for collecting, searching, and visualizing logs.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "Platform for searching, monitoring, and analyzing machine-generated data, including logs.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Graylog",
        "Description": "Open-source log management platform with advanced log analysis and visualization capabilities.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fluentd",
        "Description": "Open-source data collector for unified logging and log processing.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Loggly",
        "Description": "Cloud-based log management and analytics service for real-time log analysis.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Papertrail",
        "Description": "Cloud-hosted log management service for centralized log analysis and monitoring.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Datadog Logs",
        "Description": "Logging service integrated with Datadog's monitoring platform for comprehensive log analysis.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Not aware of attacks happening.",
    "Measure": "Check logs for keywords.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "",
    "ISO 27001:2017": "ISO 27001:2017 mapping is missing",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test of virtualized environments",
    "Level": "2",
    "Description": "Testing virtualized environments involves verifying that virtual machines and containers are configured securely and operate within defined security parameters. This ensures that the virtual infrastructure is resilient, compliant with security standards, and free from misconfigurations that could lead to vulnerabilities. Pipeline-compatible tools like Docker, Kubernetes, Ansible, and Terraform can automate the testing and validation of virtualized environments within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Docker",
        "Description": "Platform for developing, shipping, and running applications in containers, essential for virtual environment testing.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that facilitates the testing and validation of containerized environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "Automation tool for configuring and managing virtual environments securely.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Puppet",
        "Description": "Configuration management tool that automates the provisioning and hardening of virtual environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Chef",
        "Description": "Automation platform for managing infrastructure and ensuring secure virtual environment configurations.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code tool that supports the provisioning and testing of secure virtual environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "VirtualBox",
        "Description": "Open-source virtualization tool for testing and verifying virtual environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "VMware vSphere",
        "Description": "Virtualization platform for managing virtual machines and ensuring secure configurations.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Virtualized environments (e.g. via <i>Container Images</i>) might contains unsecure configurations.",
    "Measure": "Test virtualized environments for unsecured configurations.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "ISO 27001:2017 mapping is missing",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "App. Hardening Level 1",
    "Level": "2",
    "Description": "Application Hardening Level 1 involves implementing basic security measures to protect applications from common threats. This includes practices like input validation, error handling, and enforcing secure coding standards. Pipeline-compatible tools like ESLint, SonarQube, and OWASP ZAP can automate the enforcement of these basic security measures within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "Linting tool for JavaScript that enforces coding standards and identifies security vulnerabilities.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for quality and security issues, supporting basic hardening practices.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can identify basic security vulnerabilities during CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Using an insecure application might lead to a compromised application. This might lead to total data theft or data modification.",
    "Measure": "Following frameworks like the * OWASP Application Security Verification Standard Level 1 * OWASP Mobile Application Security Verification Standard in all applications provides a good baseline. Implement 95%-100% of the recommendations.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "D-SR-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "App. Hardening Level 1 (50%)",
    "Level": "1",
    "Description": "Application Hardening Level 1 (50%) signifies partial implementation of basic security measures to protect applications. This includes some practices like input validation and error handling but may lack comprehensive coverage. Pipeline-compatible tools like ESLint and SonarQube can assist in automating the enforcement of these partial security measures within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "Linting tool for JavaScript that can enforce partial coding standards and identify some security vulnerabilities.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that can analyze code for partial quality and security issues.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Using an insecure application might lead to a compromised application. This might lead to total data theft or data modification.",
    "Measure": "Following frameworks like the * OWASP Application Security Verification Standard Level 1 * OWASP Mobile Application Security Verification Standard in all applications provides a good baseline. Implement 50% of the recommendations.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "D-SR-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Hardening of the Environment",
    "Level": "4",
    "Description": "Hardening the environment involves applying comprehensive security measures to systems and infrastructure to reduce vulnerabilities and protect against threats. This includes configuring secure settings, removing unnecessary services, and implementing robust access controls. Pipeline-compatible tools like Ansible, Puppet, and Chef can automate the hardening process within CI/CD pipelines to ensure consistent and secure configurations across environments.",
    "Tools": [
      {
        "Name": "Ansible",
        "Description": "Automation tool that can enforce comprehensive security configurations and hardening measures across multiple systems within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["YAML"]
      },
      {
        "Name": "Puppet",
        "Description": "Configuration management tool that automates the application of advanced security hardening measures across environments.",
        "Opensource": true,
        "Languages": ["Ruby"]
      },
      {
        "Name": "Chef",
        "Description": "Automation platform that can manage and enforce comprehensive security hardening configurations within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["Ruby"]
      }
    ],
    "Risk": "Using default configurations for a cluster environment leads to potential risks.",
    "Measure": "Harden environments according to best practices. Level 2 and partially level 3 from hardening practices like 'CIS Kubernetes Bench for Security' should be considered.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "WAF Advanced",
    "Level": "5",
    "Description": "Advanced Web Application Firewall (WAF) implementation involves deploying sophisticated WAF solutions that provide enhanced security features such as real-time threat detection, automated rule updates, and integration with CI/CD pipelines for continuous protection. Tools like AWS WAF, Cloudflare WAF, and Imperva offer advanced capabilities that can be integrated into DevSecOps workflows to ensure robust application security.",
    "Tools": [
      {
        "Name": "AWS WAF",
        "Description": "A scalable WAF service that protects web applications from common web exploits and integrates seamlessly with AWS CI/CD tools.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Cloudflare WAF",
        "Description": "Provides advanced threat protection for web applications with automated rule updates and integration capabilities for CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Imperva",
        "Description": "Delivers comprehensive WAF solutions with real-time threat intelligence and CI/CD pipeline integration for continuous security.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "The presence of sophisticated threats necessitates a robust defense strategy where application inputs are meticulously scrutinized for security breaches, including advanced persistent threats and zero-day vulnerabilities.",
    "Measure": "An advanced WAF protection level includes rigorous input validation, rejecting any parameters not explicitly required, and custom rule sets that are dynamically updated in response to emerging threats.",
    "Knowledge": "",
    "Resources": "",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "D-SR-3-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Local development security checks performed",
    "Level": "3",
    "Description": "Performing local development security checks involves implementing security testing and validation during the development phase on local environments. This practice ensures that security issues are identified and addressed early in the development process. Tools like Git hooks with security linters, Pre-commit hooks, and IDE-integrated security plugins can be used to automate local security checks within DevSecOps workflows.",
    "Tools": [
      {
        "Name": "Git hooks",
        "Description": "Scripts that run automatically during Git operations to enforce security checks, integrated into local development environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Pre-commit",
        "Description": "A framework for managing and maintaining multi-language pre-commit hooks, enabling automated security checks in local development.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Creating and developing code contains code smells and quality issues.",
    "Measure": "Integration of quality and linting plugins with interactive development environment (IDEs). Implement pre-commit checks to prevent secrets & other security issues being commit to source code.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Weak password test",
    "Level": "3",
    "Description": "Conducting weak password tests involves assessing the strength of passwords used within the infrastructure to ensure they meet security standards and are resistant to brute-force or guessing attacks. While tools like Hydra, John the Ripper, and Hashcat are effective for password cracking and strength testing, pipeline-compatible tools such as Burp Suite and OWASP ZAP can be integrated into CI/CD workflows to automate password strength assessments.",
    "Tools": [
      {
        "Name": "Burp Suite",
        "Description": "Web vulnerability scanner that includes password strength testing features and can be integrated into CI/CD pipelines for automated security assessments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can be configured for automated password strength testing within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Weak passwords in components like applications or systems, specially for privileged accounts, lead to take over of that account.",
    "Measure": "Automatic brute force attacks are performed. Specially the usage of standard accounts like 'admin' and employee user-ids is recommended.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "9/3/2003",
    "ISO 27001:2022": "5.17"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Role based authentication and authorization",
    "Level": "3",
    "Description": "Implementing role-based authentication and authorization involves defining user roles and permissions to control access to resources within the infrastructure. This ensures that users have only the necessary permissions to perform their tasks, minimizing the risk of unauthorized access. Pipeline-compatible tools such as AWS IAM, Keycloak, and Azure Active Directory can be integrated into CI/CD workflows to automate role management.",
    "Tools": [
      {
        "Name": "AWS IAM (Identity and Access Management)",
        "Description": "Provides role-based access control and fine-grained permissions for managing resources in AWS environments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Keycloak",
        "Description": "Open-source identity and access management tool for securing applications and services.",
        "Opensource": true,
        "Languages": ["Java", "JavaScript"]
      },
      {
        "Name": "Azure Active Directory",
        "Description": "Microsoft's cloud-based identity and access management service, offering role-based access control and integration with various DevOps tools.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Everyone is able to get unauthorized access to information on systems or to modify information unauthorized on systems.",
    "Measure": "The usage of a (role based) access control helps to restrict system access to authorized users.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "9.4.1",
    "ISO 27001:2022": "8.3"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Simple access control for systems",
    "Level": "1",
    "Description": "Implementing simple access control for systems involves setting up basic authentication and authorization mechanisms to restrict access to authorized users only. While pipeline-compatible tools for basic access control are limited, standalone solutions like SSH key management and basic firewall configurations can be employed.",
    "Tools": [],
    "Risk": "Attackers a gaining access to internal systems and application interfaces",
    "Measure": "All internal systems are using simple authentication",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "9.4.1",
    "ISO 27001:2022": "8.3"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "MFA",
    "Level": "2",
    "Description": "Implementing Multi-Factor Authentication (MFA) enhances security by requiring multiple forms of verification before granting access. This reduces the risk of unauthorized access due to compromised credentials. Pipeline-compatible tools like Azure Active Directory, Okta, and Duo Security can automate MFA enforcement within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Azure Active Directory",
        "Description": "Cloud-based identity and access management service that enforces MFA for secure user authentication.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Okta",
        "Description": "Identity management service that provides MFA to secure user access across applications.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Duo Security",
        "Description": "MFA solution that integrates with various platforms to provide secure user authentication.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "One factor authentication is more vulnerable to brute force attacks and is considered less secure.",
    "Measure": "Two ore more factor authentication for all accounts on all (important) systems and applications",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "5.17,5.3,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "MFA for admins",
    "Level": "1",
    "Description": "Implementing Multi-Factor Authentication (MFA) specifically for administrators ensures that privileged accounts are secured with additional verification layers, reducing the risk of unauthorized access and potential system compromises. Pipeline-compatible tools like Azure Active Directory, Okta, and Duo Security can enforce MFA for admin accounts within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Azure Active Directory",
        "Description": "Cloud-based identity and access management service that enforces MFA for administrative accounts.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Okta",
        "Description": "Identity management service that provides MFA for securing admin access across applications.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Duo Security",
        "Description": "MFA solution that integrates with various platforms to provide secure authentication for admin accounts.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "One factor authentication is more vulnerable to brute force attacks and is considered less secure.",
    "Measure": "Two ore more factor authentication for all privileged accounts on systems and applications",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "5.17,5.3,8.25"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Ad-Hoc Security trainings for software developers",
    "Level": "1",
    "Description": "Conducting ad-hoc security trainings for software developers involves providing occasional training sessions focused on security best practices and awareness to enhance the security skills of the development team. While not directly pipeline-compatible, platforms like Pluralsight and Udemy offer security training modules that can be integrated into developer onboarding processes.",
    "Tools": [],
    "Risk": "Understanding security is hard and personnel needs to be trained on it. Otherwise, flaws like an SQL Injection might be introduced into the software which might get exploited.",
    "Measure": "Provide security awareness training for all personnel involved in software development Ad-Hoc.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "G-EG-1-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Conduction of build-it, break-it, fix-it contests",
    "Level": "3",
    "Description": "Conducting build-it, break-it, fix-it contests involves organizing events where teams build applications, attempt to break them by identifying vulnerabilities, and then fix the issues. This hands-on approach promotes practical security skills and fosters a culture of continuous improvement. While not pipeline-compatible, tools like GitHub Actions can automate parts of the contest workflows.",
    "Tools": [],
    "Risk": "Understanding security is hard, even for security champions and the conduction of security training often focuses on breaking a component instead of building a component secure.",
    "Measure": "The build-it, break-it, fix-it contest allows to train people with security related roles like security champions the build, break and fix part of a secure application. This increases the learning of building secure components.",
    "Knowledge": "",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "G-EG-2-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Office Hours",
    "Level": "3",
    "Description": "Organizing office hours involves setting aside dedicated time for team members to seek guidance, ask questions, and discuss security-related concerns with security experts or coaches, promoting an open and supportive security culture. This activity does not typically involve pipeline-compatible tools.",
    "Tools": [],
    "Risk": "Developers and Operations are not in contact with the security team and therefore do not ask prior implementation of (known or unknown) threats-",
    "Measure": "As a security team, be open for questions and hints during defined office hours. x x d",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "G-EG-1-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Regular security training for all",
    "Level": "2",
    "Description": "Providing regular security training for all employees ensures that everyone is aware of security policies, best practices, and emerging threats, fostering a security-conscious organizational culture. While pipeline-compatible tools are not directly applicable, Learning Management Systems (LMS) like Moodle or Coursera can facilitate regular training sessions.",
    "Tools": [],
    "Risk": "Understanding security is hard.",
    "Measure": "Provide security awareness training for all internal personnel involved in software development on a regular basis like twice in a year for 1-3 days.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "Very High",
    "SAMM": "G-EG-1-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Regular security training for externals",
    "Level": "4",
    "Description": "Conducting regular security training for externals, such as contractors or third-party vendors, ensures that they adhere to the organization's security standards and understand their responsibilities in maintaining security. Tools like LinkedIn Learning and external LMS platforms can support these training initiatives.",
    "Tools": [],
    "Risk": "Understanding security is hard.",
    "Measure": "Provide security awareness training for all personnel including externals involved in software development on a regular basis.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "G-EG-3-A",
    "ISO 27001:2017": "7/1/2002",
    "ISO 27001:2022": "6.3"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Information security targets are communicated",
    "Level": "2",
    "Description": "Communicating information security targets involves clearly conveying the organization's security goals, policies, and expectations to all stakeholders, ensuring alignment and understanding across the board. This activity primarily relies on documentation and communication tools rather than pipeline-compatible tools.",
    "Tools": [],
    "Risk": "Employees don't know their organizations security targets. Therefore security is not considered during development and administration as much as it should be.",
    "Measure": "Transparent and timely communication of the security targets by senior management is essential to ensure teams' buy-in and support.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "",
    "ISO 27001:2017": "5.1.1",
    "ISO 27001:2022": "5.1,5.4"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Aligning security in teams",
    "Level": "4",
    "Description": "Aligning security in teams involves integrating security objectives and responsibilities into the workflows and culture of various teams, ensuring that security is a shared responsibility and is embedded in daily operations. Tools like Confluence and Jira can facilitate the integration of security tasks into team workflows.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Project management tool that can integrate security tasks and track their progress within team workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Confluence",
        "Description": "Collaboration tool for creating and sharing security documentation and guidelines across teams.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "The concept of Security Champions might suggest that only he/she is responsible for security. However, everyone in the project team should be responsible for security.",
    "Measure": "By aligning security Subject Matter Experts with project teams, a higher security standard can be achieved.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Low",
    "Time": "Very High",
    "Usefulness": "",
    "SAMM": "G-EG-3-B",
    "ISO 27001:2017": "7.1.1",
    "ISO 27001:2022": "6.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage of sequential operations",
    "Level": "3",
    "Description": "Ensuring coverage of sequential operations involves testing the execution of processes that occur in a specific order within the application. This helps in identifying vulnerabilities and ensuring the correct functioning of multi-step workflows. Pipeline-compatible tools like Selenium, Cypress, and JUnit can automate the testing of sequential operations within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Selenium",
        "Description": "Automation tool for testing web applications, including sequential operation workflows within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "Python", "C#"]
      },
      {
        "Name": "Cypress",
        "Description": "End-to-end testing framework that automates the testing of sequential operations within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "JUnit",
        "Description": "Java testing framework that can automate the testing of sequential operations within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java"]
      }
    ],
    "Risk": "Sequential operations like workflows (e.g. login -> put products in the basket",
    "Measure": "Sequential operations are defined and checked by the vulnerability scanner in the defined order.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage of service to service communication",
    "Level": "5",
    "Description": "Ensuring coverage of service-to-service communication involves thoroughly testing the interactions between different microservices or components within the application. This enhances the reliability and security of the overall system by identifying and addressing vulnerabilities in inter-service communication. Pipeline-compatible tools like Postman, SoapUI, and Pact can automate the testing of service-to-service interactions within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Postman",
        "Description": "API testing tool that can automate the testing of service-to-service communication within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "SoapUI",
        "Description": "API testing tool for SOAP and REST services that can automate service-to-service communication tests within CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Pact",
        "Description": "Consumer-driven contract testing tool that ensures reliable service-to-service interactions within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Service to service communication is not covered.",
    "Measure": "Service to service communication is dumped and checked.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Simple Scan",
    "Level": "2",
    "Description": "Conducting simple scans involves performing basic security and vulnerability assessments on the application to identify common issues. This helps in maintaining a baseline level of security and ensuring that fundamental vulnerabilities are addressed. Pipeline-compatible tools like OWASP ZAP, Nessus, and Nikto can automate simple scans within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can perform simple vulnerability scans within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Nessus",
        "Description": "Vulnerability assessment tool that can automate simple security scans within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Nikto",
        "Description": "Open-source web server scanner that performs comprehensive tests against web servers for multiple items, including over 6700 potentially dangerous files.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Burp Suite",
        "Description": "A comprehensive web vulnerability scanner for identifying and addressing security issues in web applications.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Arachni",
        "Description": "An open-source tool designed to identify vulnerabilities in web applications.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Qualys Web Application Scanner",
        "Description": "Cloud-based service for identifying vulnerabilities in web applications.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Deficient security tests are performed. Simple vulnerabilities are not detected and missing security configurations (e.g. headers) are not set. Fast feedback is not given.",
    "Measure": "A simple scan is performed to get a security baseline. In case the test is done in under 10 minutes, it should be part of the build and deployment process.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Low",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "Building and testing of artifacts in virtual environments",
    "Level": "2",
    "Description": "Building and testing artifacts in virtual environments involves creating isolated environments where software artifacts are compiled, built, and tested to ensure functionality and security before deployment. This process mitigates risks associated with malicious third-party systems, vulnerable libraries, or altered components during the delivery phase. Pipeline-compatible tools such as Jenkins, GitLab CI/CD, CircleCI, and Azure Pipelines can automate the build and test processes within CI/CD pipelines, enhancing security and consistency. Additionally, containerization tools like Docker and orchestration tools like Kubernetes provide isolated environments for secure artifact management.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that enables developers to build, test, and deploy applications automatically, integrating seamlessly into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "A built-in continuous integration and continuous deployment tool within GitLab that automates the building, testing, and deployment of applications.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "CircleCI",
        "Description": "A continuous integration and delivery platform that automates the build, test, and deployment processes, supporting various languages and frameworks.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Pipelines",
        "Description": "A cloud service that supports building, testing, and deploying code automatically across multiple platforms and environments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Docker",
        "Description": "A platform that enables developers to containerize applications, ensuring consistency across multiple environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "An open-source system for automating the deployment, scaling, and management of containerized applications.",
        "Opensource": true,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "Pinning of artifacts",
    "Level": "2",
    "Description": "Pinning of artifacts ensures that only specific, approved versions of dependencies and libraries are used during the build and deployment processes. This practice prevents unauthorized or unintended manipulation of artifacts, which could introduce malicious code or break functionality. By locking dependencies to known, secure versions, the integrity of the artifacts is maintained throughout the delivery pipeline.",
    "Tools": [
      {
        "Name": "Dependabot",
        "Description": "A GitHub-native tool that automatically scans for dependency updates and ensures that projects use secure and up-to-date libraries.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Renovate",
        "Description": "An open-source tool that automates dependency updates, ensuring that projects use the latest secure versions of libraries and frameworks.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "A security tool that scans and monitors dependencies for vulnerabilities, integrating seamlessly into CI/CD pipelines to enforce artifact pinning.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Artifactory",
        "Description": "A universal artifact repository manager that supports various package formats and integrates with CI/CD pipelines to manage and pin artifact versions.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "Defined build process",
    "Level": "1",
    "Description": "A defined build process establishes standardized procedures for compiling, building, and packaging software artifacts. This reduces the likelihood of errors and security misconfigurations by ensuring that each step is consistently executed. Implementing a well-defined build process enhances the reliability and security of the software delivery pipeline.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that facilitates the creation of defined build pipelines, ensuring consistency and automation in the build process.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Provides predefined pipelines and configuration files to establish a consistent build process across different projects.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Azure Pipelines",
        "Description": "Offers configurable build pipelines that standardize the build process across various environments and projects.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "TeamCity",
        "Description": "A powerful CI server from JetBrains that allows the definition of detailed build processes with extensive customization options.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "SBOM of components",
    "Level": "2",
    "Description": "Creation of a Software Bill of Materials (SBOM) involves documenting all components, dependencies, and their versions used in the application and container images during the build process. This allows for the identification and management of vulnerabilities by providing a clear inventory of all parts of the software. Pipeline-compatible tools like CycloneDX, SPDX, and Syft can automate SBOM generation within CI/CD pipelines, ensuring up-to-date and accurate component tracking.",
    "Tools": [
      {
        "Name": "CycloneDX",
        "Description": "A lightweight SBOM standard designed for use in application security contexts and supply chain component analysis.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "SPDX",
        "Description": "An open standard for communicating software bill of material information, enabling consistent and accurate component documentation.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Syft",
        "Description": "A CLI tool and Go library for generating SBOMs for container images and filesystems, integrating easily into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Anchore",
        "Description": "A tool for deep container inspection and SBOM generation, ensuring that all components meet security and compliance standards.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Evaluation of the trust of used components",
    "Level": "2",
    "Description": "Evaluating the trustworthiness of used components ensures that all software and system dependencies are secure and reliable. This involves assessing the source, maintainers, and overall integrity of each component. Pipeline-compatible tools like Black Duck, Snyk, and Sonatype Nexus Lifecycle can automate the evaluation and enforce policies to whitelist trusted artifacts.",
    "Tools": [
      {
        "Name": "Black Duck",
        "Description": "A comprehensive open-source management solution that identifies and mitigates security, license, and operational risks.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "A security platform that finds and fixes vulnerabilities in dependencies and container images.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Sonatype Nexus Lifecycle",
        "Description": "A tool that provides governance and policy enforcement for managing open-source components throughout the development lifecycle.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Application and system components like Open Source libraries or images can have implementation flaws or deployment flaws. Developers or operations might start random images in the production cluster which have malicious code or known vulnerabilities.",
    "Measure": "Each component's source is evaluated to be trusted. For example, the source, number of developers included, email configuration used by maintainers to prevent maintainer account theft, typo-squatting, etc. Create image assessment criteria, perform an evaluation of images, and create a whitelist of artifacts/container images/virtual machine images.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.5",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.25,8.27"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Conduction of advanced threat modeling",
    "Level": "4",
    "Description": "Advanced threat modeling involves systematically identifying and evaluating potential security threats to the system by reviewing user stories and creating security-driven data flow diagrams. This comprehensive approach ensures that both business and technical risks are adequately identified and mitigated early in the design phase, enhancing the overall security posture of the application.",
    "Tools": [
      {
        "Name": "Microsoft Threat Modeling Tool",
        "Description": "A tool that helps in creating data flow diagrams and identifying potential threats using predefined templates and methodologies.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "ThreatModeler",
        "Description": "An automated threat modeling solution that integrates with existing development workflows to identify and mitigate security threats.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OWASP Threat Dragon",
        "Description": "An open-source threat modeling tool that allows teams to create and analyze threat models collaboratively.",
        "Opensource": true,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Design",
    "Activity": "Conduction of simple threat modeling on business level",
    "Level": "3",
    "Description": "Simple threat modeling at the business level involves identifying potential security threats related to business functionalities during the product backlog creation. This early detection helps in addressing security defects before they propagate further into the development and deployment processes, ensuring that business-related security risks are managed proactively.",
    "Tools": [
      {
        "Name": "OWASP Threat Dragon",
        "Description": "An open-source tool suitable for simple threat modeling tasks, allowing teams to collaboratively identify and mitigate business-level threats.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Microsoft Threat Modeling Tool",
        "Description": "Can be used for both simple and advanced threat modeling, providing templates and guidance for business-level security assessments.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Local development linting & style checks performed",
    "Level": "5",
    "Description": "Integrating static code analysis tools within Integrated Development Environments (IDEs) ensures that code adheres to defined linting and style guidelines. This practice helps in maintaining a secure and maintainable codebase by identifying potential security vulnerabilities and code quality issues early in the development process.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "A pluggable linting utility for JavaScript and TypeScript, helping developers identify and fix problems in their code.",
        "Opensource": true,
        "Languages": ["JavaScript", "TypeScript"]
      },
      {
        "Name": "Pylint",
        "Description": "A static code analysis tool for Python that looks for programming errors, helps enforce a coding standard, and sniffs for code smells.",
        "Opensource": true,
        "Languages": ["Python"]
      },
      {
        "Name": "Rubocop",
        "Description": "A Ruby static code analyzer and formatter, based on the community Ruby style guide.",
        "Opensource": true,
        "Languages": ["Ruby"]
      },
      {
        "Name": "StyleCop",
        "Description": "Analyzes C# source code to enforce a set of style and consistency rules.",
        "Opensource": true,
        "Languages": ["C#"]
      },
      {
        "Name": "Checkstyle",
        "Description": "A development tool to help programmers write Java code that adheres to a coding standard.",
        "Opensource": true,
        "Languages": ["Java"]
      },
      {
        "Name": "SonarLint",
        "Description": "An IDE extension that provides on-the-fly feedback to developers on code quality and security issues.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "App. Hardening Level 2",
    "Level": "4",
    "Description": "Application Hardening Level 2 involves implementing advanced security measures to protect applications from a broader range of threats. This includes practices like implementing security headers, using secure authentication mechanisms, and ensuring proper session management. Pipeline-compatible tools like OWASP ZAP, Fortify, and Snyk can automate the enforcement of these advanced security measures within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can identify advanced security vulnerabilities during CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Comprehensive security tool that performs static and dynamic analysis to identify and mitigate advanced security vulnerabilities.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that scans for vulnerabilities in dependencies and container images, supporting advanced hardening.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Using an insecure application might lead to a compromised application. This might lead to total data theft or data modification.",
    "Measure": "Following frameworks like the * OWASP Application Security Verification Standard Level 2 * OWASP Mobile Application Security Verification Standard Level 2 Implement 95%-100% of the recommendations.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "D-SR-2-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "App. Hardening Level 2 (75%)",
    "Level": "3",
    "Description": "Application Hardening Level 2 (75%) indicates substantial implementation of advanced security measures to protect applications. This includes comprehensive practices like enforcing strong authentication, implementing robust authorization controls, and ensuring secure data storage. Pipeline-compatible tools like OWASP ZAP, Fortify, and Snyk can assist in automating these advanced security measures within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can identify advanced security vulnerabilities during CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Comprehensive security tool that performs static and dynamic analysis to identify and mitigate advanced security vulnerabilities.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that scans for vulnerabilities in dependencies and container images, supporting advanced hardening.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Using an insecure application might lead to a compromised application. This might lead to total data theft or data modification.",
    "Measure": "Following frameworks like the * OWASP Application Security Verification Standard Level 2 * OWASP Mobile Application Security Verification Standard Level 2 Implement 75% of the recommendations.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "D-SR-2-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "App. Hardening Level 3",
    "Level": "5",
    "Description": "Application Hardening Level 3 represents the full implementation of advanced security measures to protect applications comprehensively. This includes integrating security into every stage of the development lifecycle, continuous monitoring, and adopting a security-first approach. Pipeline-compatible tools like OWASP ZAP, Fortify, Snyk, and SonarQube can automate and enforce these comprehensive security measures within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that identifies comprehensive security vulnerabilities during CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Comprehensive security tool that performs extensive static and dynamic analysis to identify and mitigate all security vulnerabilities.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that scans for vulnerabilities in dependencies and container images, supporting full-scale hardening.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that provides in-depth analysis of code quality and security, supporting comprehensive hardening efforts.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Using an insecure application might lead to a compromised application. This might lead to total data theft or data modification.",
    "Measure": "Following frameworks like the * OWASP Application Security Verification Standard Level 3 * OWASP Mobile Application Security Verification Standard Implement 95%-100% of the recommendations.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "Very High",
    "SAMM": "D-SR-3-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Application Hardening",
    "Activity": "Contextualized Encoding",
    "Level": "1",
    "Description": "Contextualized Encoding involves encoding data based on its context to prevent security vulnerabilities like injection attacks. This ensures that data is handled securely depending on where and how it is used within the application. Pipeline-compatible tools like ESLint and SonarQube can assist in enforcing encoding standards within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "Linting tool for JavaScript that can enforce contextual encoding practices to prevent injection attacks.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for proper encoding practices based on context to prevent security vulnerabilities.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "The generation of interpreter directives from user-provided data poses difficulties and can introduce vulnerabilities to injection attacks.",
    "Measure": "Implementing contextualized encoding, such as employing object-relational mapping tools or utilizing prepared statements, nearly removes the threat of injection vulnerabilities.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "D-SR-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "WAF baseline",
    "Level": "3",
    "Description": "WAF baseline implementation involves setting up a fundamental Web Application Firewall configuration that provides essential protection against common threats. This baseline serves as the foundation for further security enhancements and can be integrated into DevSecOps pipelines using tools like AWS WAF, Cloudflare WAF, and ModSecurity to automate baseline rule deployments and updates.",
    "Tools": [
      {
        "Name": "AWS WAF",
        "Description": "Enables the establishment of baseline security rules for web applications, integrated with AWS CI/CD tools.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Cloudflare WAF",
        "Description": "Provides essential WAF protection with baseline rule sets that can be automated through CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "ModSecurity",
        "Description": "An open-source WAF that offers baseline protection rules and can be integrated into various CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerable input, such as exploits, can infiltrate the application via numerous entry points, posing a significant security threat.",
    "Measure": "Implementing a web application firewall (WAF) is a critical security control. At a baseline level, the objective is to finely balance the reduction of false positives, maintaining user experience, against a potential increase in the less noticeable false negatives.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "D-SR-3-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "WAF medium",
    "Level": "4",
    "Description": "Medium-level WAF implementation includes deploying WAF configurations with enhanced security rules and monitoring capabilities. This level provides improved protection against a wider range of threats and integrates with CI/CD pipelines for automated updates and continuous monitoring. Tools like AWS WAF, Cloudflare WAF, and Imperva can be configured for medium-level security, offering features like custom rule creation and real-time traffic analysis.",
    "Tools": [
      {
        "Name": "AWS WAF",
        "Description": "Offers medium-level security configurations with custom rules and real-time traffic monitoring, integrated into AWS CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Cloudflare WAF",
        "Description": "Provides advanced WAF features with customizable rules and automated integration with CI/CD pipelines for continuous protection.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Imperva",
        "Description": "Delivers medium-level WAF configurations with enhanced threat detection and CI/CD pipeline integration for ongoing security management.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "The threat from malicious inputs remains high, with exploits seeking to exploit any vulnerabilities present at the various points of entry to the application.",
    "Measure": "A WAF deployed with a medium level of protection strengthens the security posture by striking a more advanced balance between the detection of genuine threats and the minimization of false alarms.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Very High",
    "Time": "",
    "Usefulness": "High",
    "SAMM": "D-SR-3-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "Hardening is not explicitly covered by ISO 27001 - too specific,8.22"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Environment depending configuration parameters (secrets)",
    "Level": "2",
    "Description": "Managing environment-dependent configuration parameters, especially secrets, is crucial for maintaining security. Using environment variables stored in platform-specific functionalities or secrets management systems ensures that sensitive information is protected. Pipeline-compatible tools like HashiCorp Vault, AWS Secrets Manager, and Kubernetes Secrets automate the management and injection of secrets into deployment environments.",
    "Tools": [
      {
        "Name": "HashiCorp Vault",
        "Description": "A tool for securely accessing secrets, managing sensitive data, and controlling access to systems.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Secrets Manager",
        "Description": "A service that helps you protect access to your applications, services, and IT resources without the upfront cost and complexity of managing your own hardware security module (HSM) infrastructure.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Kubernetes Secrets",
        "Description": "A Kubernetes resource object that stores sensitive information, such as passwords, OAuth tokens, and SSH keys.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Unauthorized access to secrets stored in source code or in artifacts (e.g. container images) through process listing (e.g. ps -ef).",
    "Measure": "Set configuration parameters via environment variables stored using specific platform functionalities or secrets management systems (e.g. Kubernetes secrets or Hashicorp Vault).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-1-B",
    "ISO 27001:2017": "14.2.6",
    "ISO 27001:2022": "8.4,8.31"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Handover of confidential parameters",
    "Level": "3",
    "Description": "Handover of confidential parameters involves securely transferring sensitive credentials and configuration data to deployment environments. Encryption and credential management systems are essential to protect these parameters from unauthorized access. Pipeline-compatible tools like HashiCorp Vault, AWS Secrets Manager, and Azure Key Vault facilitate secure handling and distribution of confidential parameters within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "HashiCorp Vault",
        "Description": "A tool for securely accessing secrets, managing sensitive data, and controlling access to systems.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Secrets Manager",
        "Description": "A service that helps you protect access to your applications, services, and IT resources without the upfront cost and complexity of managing your own hardware security module (HSM) infrastructure.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Key Vault",
        "Description": "A cloud service for securely storing and accessing secrets, keys, and certificates.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Parameters are often used to set credentials, for example by starting containers or applications; these parameters can often be seen by any one listing running processes on the target system.",
    "Measure": "Encryption ensures confidentiality of credentials e.g. from unauthorized access on the file system. Also, the usage of a credential management system can help protect credentials.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-B",
    "ISO 27001:2017": "14.1.3",
    "ISO 27001:2022": "8.33,8.22,5.17,8.3,8.24"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Simple mob hacking",
    "Level": "3",
    "Description": "Conducting simple mob hacking sessions involves organizing interactive team activities where participants collaboratively work on identifying and exploiting vulnerabilities in a controlled environment. These sessions enhance the team's understanding of security principles and improve their ability to recognize and mitigate security threats effectively.",
    "Tools": [],
    "Languages": []
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Security Coaching",
    "Level": "3",
    "Description": "Security coaching involves guiding teams through security best practices and methodologies to help them internalize security habits within their development processes. By using structured coaching methods, such as the SAMM (Software Assurance Maturity Model) coaching method, teams can adopt and maintain robust security practices, leading to improved overall security posture.",
    "Tools": [
      {
        "Name": "SAMM (Software Assurance Maturity Model)",
        "Description": "A framework that provides organizations with a means to analyze and improve their software security posture through targeted coaching and assessment.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Secure Code Warrior",
        "Description": "A platform that offers security-focused coding training and coaching to help developers write secure code.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Block force pushes",
    "Level": "3",
    "Description": "Blocking force pushes involves preventing users from overwriting commit history in the version control system, ensuring the integrity and traceability of the codebase. This enhances security by avoiding unauthorized or accidental changes that could introduce vulnerabilities. Pipeline-compatible tools like GitHub, GitLab, and Bitbucket can enforce branch protection rules to block force pushes within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "GitHub",
        "Description": "Version control platform that can enforce branch protection rules to block force pushes and ensure code integrity.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab",
        "Description": "Integrated DevOps platform that allows setting branch protection to block force pushes and maintain commit history.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Bitbucket",
        "Description": "Git repository management solution that can configure branch permissions to block force pushes.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Misuse of force push can lead to loss of work. It may overwrite remote branches without warning, potentially erasing valuable contributions from team members. This can disrupt collaboration, cause data loss, and create confusion in the development process. Bypassing the pull request process might remove an important code review step. This increases the risk of merging low-quality or buggy code into the main branch, potentially introducing bugs in the codebase.",
    "Measure": "Mandate blocking of force pushes in the version control platform.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "5.3,8.25"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Development and Source Control",
    "Activity": "Require status checks to pass",
    "Level": "3",
    "Description": "Requiring status checks to pass before merging ensures that all automated tests, security scans, and quality assessments have successfully completed, maintaining high code standards. Pipeline-compatible tools like GitHub Actions, GitLab CI/CD, and Jenkins can enforce status checks within CI/CD workflows.",
    "Tools": [
      {
        "Name": "GitHub Actions",
        "Description": "CI/CD tool that can enforce status checks by running automated tests and scans before allowing merges.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Integrated CI/CD tool that can enforce status checks by running automated pipelines before merging code changes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate status checks by running automated tasks before permitting merges.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Organizations risk introducing broken builds, quality issues, and security vulnerabilities into their codebase.",
    "Measure": "Mandate passing of security related specified status checks, like successful builds or static application security tests, before proceeding.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "5.3,8.25"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Blue/Green Deployment",
    "Level": "5",
    "Description": "Blue/Green Deployment is a strategy that reduces deployment risk by running two identical production environments called Blue and Green. This allows for seamless switching between environments during deployments. Pipeline-compatible tools like Kubernetes, AWS Elastic Beanstalk, and Spinnaker facilitate Blue/Green deployments by automating the routing and switching processes.",
    "Tools": [
      {
        "Name": "Kubernetes",
        "Description": "An open-source container orchestration system for automating application deployment, scaling, and management.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Elastic Beanstalk",
        "Description": "An easy-to-use service for deploying and scaling web applications and services developed with various languages.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Spinnaker",
        "Description": "An open-source multi-cloud continuous delivery platform for releasing software changes with high velocity and confidence.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "A new artifact's version can have unknown defects.",
    "Measure": "Using a blue/green deployment strategy increases application availability and reduces deployment risk by simplifying the rollback process if a deployment fails.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "TODO",
    "ISO 27001:2017": "14.2.9",
    "ISO 27001:2022": "8.14,5.37,8.31,8.32,8.19,8.29"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Rolling update on deployment",
    "Level": "3",
    "Description": "Implementing rolling updates involves updating applications incrementally across servers or instances to minimize downtime and ensure continuous availability. This approach allows for seamless deployments and quick rollbacks in case of issues. Pipeline-compatible tools like Kubernetes, Terraform, and Jenkins can automate rolling updates within CI/CD pipelines, ensuring smooth and reliable deployments.",
    "Tools": [
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that manages rolling updates to ensure seamless application deployments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code tool that can automate rolling updates by managing infrastructure changes incrementally within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["HCL"]
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate rolling updates through pipeline scripts and plugins.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "While a deployment is performed, the application can not be reached.",
    "Measure": "A deployment without downtime is performed*.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "I-SD-1-A",
    "ISO 27001:2017": "12.5.1",
    "ISO 27001:2022": "8.19,8.32,8.14"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Process",
    "Activity": "Definition of simple BCDR practices for critical components",
    "Level": "1",
    "Description": "Defining simple Business Continuity and Disaster Recovery (BCDR) practices for critical components involves documenting clear procedures and responsibilities to ensure system and application availability during emergencies. This includes outlining recovery point objectives (RPOs), recovery time objectives (RTOs), service level agreements (SLAs), and failover strategies to minimize downtime and ensure rapid restoration of services.",
    "Tools": [
      {
        "Name": "Azure Site Recovery",
        "Description": "A disaster recovery solution that ensures business continuity by keeping business apps and workloads running during outages.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Veeam Backup & Replication",
        "Description": "Provides backup, recovery, and replication solutions to ensure data availability and disaster recovery.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Disaster Recovery Plan Templates (various)",
        "Description": "Predefined templates that help organizations document their BCDR strategies and procedures effectively.",
        "Opensource": true,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Education and Guidance",
    "Activity": "Security-Lessoned-Learned",
    "Level": "3",
    "Description": "Conducting 'lessons learned' sessions after security incidents involves analyzing the events to understand what went wrong and how similar incidents can be prevented in the future. These sessions promote continuous improvement by sharing insights and strategies with the team, thereby enhancing the organization's ability to respond to and recover from security incidents effectively.",
    "Tools": [
      {
        "Name": "Post-Incident Review Tools",
        "Description": "Tools like Confluence or SharePoint can be used to document and share lessons learned from security incidents.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Root Cause Analysis Tools",
        "Description": "Software like RCA tools help in identifying the underlying causes of incidents to prevent recurrence.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Same artifact for environments",
    "Level": "4",
    "Description": "Building an artifact once and deploying it to different environments ensures that only tested and verified artifacts reach the production environment, reducing the risk of introducing untested changes into production.",
    "Tools": [
      {
        "Name": "Docker",
        "Description": "A platform for developing, shipping, and running applications in containers, ensuring consistency across environments.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "An open-source container orchestration system for automating application deployment, scaling, and management.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Terraform",
        "Description": "An open-source infrastructure as code software tool that provides a consistent CLI workflow to manage hundreds of cloud services.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Building of an artifact for different environments means that an untested artifact might reach the production environment.",
    "Measure": "Building an artifact once and deploying it to different environments means that only tested artifacts are allowed to reach the production environment",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-A",
    "ISO 27001:2017": "14.3.1",
    "ISO 27001:2022": "8.33,8.29,8.31"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Usage of feature toggles",
    "Level": "4",
    "Description": "Feature toggles allow for the enabling or disabling of features in different environments without deploying new code. Using environment-independent configuration parameters, known as static feature toggles, mitigates the risk of accidentally enabling insecure features in production. Pipeline-compatible tools like LaunchDarkly, Unleash, and FeatureToggle can automate the management and deployment of feature toggles within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "LaunchDarkly",
        "Description": "A feature management platform that allows teams to control feature releases with feature flags.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Unleash",
        "Description": "An open-source feature toggle system that provides full control over feature releases.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "FeatureToggle",
        "Description": "A tool for managing feature flags and toggles within applications to control feature visibility.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Using environment variables to enable or disable features can lead to a situation where a feature is accidentally enabled in the production environment.",
    "Measure": "Usage of environment independent configuration parameter, called static feature toggles, mitigates the risk of accidentally enabling insecure features in production.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "",
    "ISO 27001:2017": "14.3.1",
    "ISO 27001:2022": "8.33,8.29,8.31"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Test-Intensity",
    "Activity": "Regular automated tests",
    "Level": "2",
    "Description": "Implementing regular automated tests involves scheduling and executing a suite of tests consistently to ensure ongoing code quality and security. This practice helps in early detection of issues and maintains the reliability of the application. Pipeline-compatible tools like Jenkins, GitLab CI/CD, and GitHub Actions can automate the execution of regular tests within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Automation server that can schedule and run regular automated tests as part of the CI/CD pipeline.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Integrated CI/CD tool that can automate the execution of regular test suites within deployment workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitHub Actions",
        "Description": "CI/CD tool that can automate regular test executions through workflow configurations.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "After pushing source code to the version control system, any delay in receiving feedback on defects makes them harder for the developer to remediate.",
    "Measure": "On each push and/or at given intervals automatic security tests are performed.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "I-SB-3-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Load tests",
    "Level": "4",
    "Description": "Load tests involve simulating high traffic and usage scenarios to evaluate how infrastructure and applications perform under stress. This ensures that systems can handle peak loads without performance degradation or failures. Tools like JMeter, Locust, and Gatling can be integrated into DevSecOps pipelines to automate load testing and performance evaluation.",
    "Tools": [
      {
        "Name": "JMeter",
        "Description": "An open-source tool designed to load test functional behavior and measure performance, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Locust",
        "Description": "An open-source load testing tool that allows writing test scenarios in Python, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": ["Python"]
      },
      {
        "Name": "Gatling",
        "Description": "A high-performance load testing tool that uses Scala for writing test scenarios, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Scala"]
      }
    ],
    "Risk": "As it is unknown how many requests the systems and applications can serve, due to an unexpected load the availability is disturbed.",
    "Measure": "Load test against the production system or a production near system is performed.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6,8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Test for exposed services",
    "Level": "2",
    "Description": "Testing for exposed services involves identifying and assessing services that are accessible externally to ensure they are secure and do not expose vulnerabilities. This process helps in minimizing the attack surface by controlling and securing exposed endpoints. Tools like Nmap, Shodan, and OpenVAS can be integrated into DevSecOps pipelines to automate the detection and assessment of exposed services.",
    "Tools": [
      {
        "Name": "Nmap",
        "Description": "A network scanning tool used to discover exposed services and assess their security within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Shodan",
        "Description": "A search engine for internet-connected devices that can be used to identify exposed services and vulnerabilities, compatible with CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OpenVAS",
        "Description": "An open-source vulnerability scanner that detects exposed services and assesses their security within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Standard network segmentation and firewalling has not been performed, leading to world open cluster management ports.",
    "Measure": "With the help of tools the network configuration of unintentional exposed cluster(s) are tested. To identify clusters, all subdomains might need to be identified with a tool like OWASP Amass to perform port scans based o the result.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "8.22,8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Test for unused Resources",
    "Level": "5",
    "Description": "Testing for unused resources involves identifying and eliminating infrastructure components that are no longer in use to optimize resource utilization and reduce potential security risks. This practice helps in maintaining a lean and secure infrastructure by removing unnecessary elements. Tools like AWS Trusted Advisor, Azure Resource Manager, and Google Cloud's Resource Manager can be integrated into DevSecOps pipelines to automate the detection and management of unused resources.",
    "Tools": [
      {
        "Name": "AWS Trusted Advisor",
        "Description": "Provides recommendations for optimizing AWS resources, including identifying and managing unused resources, integrated with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Resource Manager",
        "Description": "Manages Azure resources and provides tools to identify and eliminate unused resources, compatible with CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Google Cloud Resource Manager",
        "Description": "Offers management and optimization of Google Cloud resources, including the identification of unused components within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Unused resources, specially secrets, might be still valid, but are exposing information. As an attacker, I compromise a system, gather credentials and try to use them.",
    "Measure": "Test for unused resources helps to identify unused resources.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "8.22,8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Test network segmentation",
    "Level": "2",
    "Description": "Testing network segmentation involves verifying that network boundaries are properly defined and enforced to limit access between different network segments. This enhances security by containing potential breaches and reducing the lateral movement of attackers. Tools like Wireshark, Cisco Network Analyzer, and Nmap can be integrated into DevSecOps pipelines to automate the testing and validation of network segmentation configurations.",
    "Tools": [
      {
        "Name": "Wireshark",
        "Description": "A network protocol analyzer used to verify and troubleshoot network segmentation configurations within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Cisco Network Analyzer",
        "Description": "Provides advanced network analysis and segmentation verification, compatible with CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Nmap",
        "Description": "A network scanning tool that can assess and verify network segmentation, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Wrong or no network segmentation of pods makes it easier for an attacker to access a database and extract or modify data.",
    "Measure": "Cluster internal test needs to be performed. Integration of fine granulated network segmentation (also between pods in the same namespace).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "13.1.3",
    "ISO 27001:2022": "8.22,8.32,8.29"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "Signing of artifacts",
    "Level": "5",
    "Description": "Digitally signing artifacts for all steps during the build and especially Docker images helps to ensure their integrity and authenticity. This prevents the execution or usage of malicious code or data via executables, libraries, or container images.",
    "Tools": [
      {
        "Name": "Notary",
        "Description": "An open-source tool for signing and verifying content, ensuring the integrity and provenance of artifacts.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GPG",
        "Description": "GNU Privacy Guard, a tool for secure communication and data storage, used for signing commits and artifacts.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Sigstore",
        "Description": "An open-source project that provides a transparent signing infrastructure for software artifacts.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Execution or usage of malicious code or data e.g. via executables, libraries or container images.",
    "Measure": "Digitally signing artifacts for all steps during the build and especially docker images, helps to ensure their integrity and authenticity.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SB-1-A",
    "ISO 27001:2017": "14.2.6",
    "ISO 27001:2022": "8.31"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Build",
    "Activity": "Signing of code",
    "Level": "3",
    "Description": "Digitally signing commits helps to prevent unauthorized manipulation of source code. This ensures that code changes are authentic and have not been tampered with, enhancing the security and integrity of the codebase.",
    "Tools": [
      {
        "Name": "GPG",
        "Description": "GNU Privacy Guard, a tool for secure communication and data storage, used for signing commits and artifacts.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Git-Commit-Signing",
        "Description": "Git's built-in support for GPG signing of commits to ensure the authenticity of code changes.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Execution or usage of malicious code or data e.g. via executables, libraries or container images.",
    "Measure": "Digitally signing commits helps to prevent unauthorized manipulation of source code.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-SB-2-A",
    "ISO 27001:2017": "14.2.6",
    "ISO 27001:2022": "8.31"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "A patch policy is defined",
    "Level": "1",
    "Description": "A patch policy for all artifacts (e.g., in images) is defined. This includes specifying how often an image is rebuilt to ensure vulnerabilities are patched in a timely manner.",
    "Tools": [],
    "Risk": "Vulnerabilities in running artifacts stay for long and might get exploited.",
    "Measure": "A patch policy for all artifacts (e.g. in images) is defined. How often is an image rebuilt?",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-B",
    "ISO 27001:2017": "14.2.5",
    "ISO 27001:2022": "8.8,8.19,8.27"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Automated PRs for patches",
    "Level": "1",
    "Description": "Fast patching of third-party components is essential. The DevOps approach is to have automated pull requests for new components, including applications, virtualized operating system components (e.g., container images), operating systems, and Infrastructure as Code/GitOps (e.g., ArgoCD based on a git repository or Terraform). Pipeline-compatible tools like Dependabot and Renovate can automate the creation of pull requests for patching dependencies.",
    "Tools": [
      {
        "Name": "Dependabot",
        "Description": "A GitHub service that automatically scans and updates dependencies to their secure and latest versions.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Renovate",
        "Description": "An open-source tool that automates dependency updates and ensures that all dependencies are pinned to specific versions.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Components with known (or unknown) vulnerabilities might stay for long and get exploited, even when a patch is available.",
    "Measure": "Fast patching of third party component is needed. The DevOps way is to have an automated pull request for new components. This includes * Applications * Virtualized operating system components (e.g. container images) * Operating Systems * Infrastructure as Code/GitOps (e.g. argocd based on a git repository or terraform)",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-B",
    "ISO 27001:2017": "14.2.5",
    "ISO 27001:2022": "8.8,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Usage of multiple scanners",
    "Level": "4",
    "Description": "Usage of multiple scanners involves employing various dynamic analysis tools to comprehensively evaluate applications for security vulnerabilities, performance issues, and compliance with best practices. This multi-scanner approach enhances the detection of diverse issues by leveraging the strengths of different tools. Tools like OWASP ZAP, Burp Suite, and Nikto can be integrated into DevSecOps pipelines to provide layered security testing and thorough application assessments.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "An open-source web application security scanner that identifies vulnerabilities through dynamic analysis, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Burp Suite",
        "Description": "A comprehensive web vulnerability scanner that performs dynamic analysis for security testing, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Nikto",
        "Description": "An open-source web server scanner that performs comprehensive tests for security vulnerabilities, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Each vulnerability scanner has different opportunities. By using just one scanner, some vulnerabilities might not be found.",
    "Measure": "Usage of multiple spiders and scanner enhance the coverage and the vulnerabilities.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "High",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "API design validation",
    "Level": "3",
    "Description": "API design validation involves verifying that the API designs meet the required specifications, adhere to best practices, and maintain security standards. This ensures that APIs are robust, maintainable, and can be effectively integrated into the overall system architecture. Tools like Postman, Swagger (OpenAPI), and Apigee can be integrated into DevSecOps pipelines to automate API testing and validation during the CI/CD process.",
    "Tools": [
      {
        "Name": "Postman",
        "Description": "A collaboration platform for API development that allows automated testing and validation of API endpoints within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Swagger (OpenAPI)",
        "Description": "A framework for API design and documentation that supports automated validation and testing of API specifications within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Apigee",
        "Description": "A full lifecycle API management platform that facilitates API design, security, and analytics, integrated into CI/CD pipelines for automated API validation.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Creation of insecure or non-compliant API.",
    "Measure": "Design contract-first APIs using an interface description language such as OpenAPI, AsyncAPI or SOAP and validate the specification using specific tools. Checks should be integrated in IDEs and CI/CD pipelines.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "14.2.1",
    "ISO 27001:2022": "8.25,8.27,8.28"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Stylistic analysis",
    "Level": "5",
    "Description": "Stylistic analysis involves enforcing coding standards and best practices to maintain code consistency, readability, and quality. This process ensures that the codebase adheres to predefined style guidelines, facilitating easier maintenance and collaboration. Tools like ESLint, Prettier, and StyleCop can be integrated into DevSecOps pipelines to automate stylistic checks and enforce coding standards during the CI/CD process.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "A static analysis tool for identifying and enforcing coding styles in JavaScript projects, easily integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "Prettier",
        "Description": "An opinionated code formatter that enforces consistent coding styles across various languages, compatible with CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "StyleCop",
        "Description": "A static analysis tool for enforcing C# coding styles and best practices, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["C#"]
      }
    ],
    "Risk": "Unclear or obfuscated code might have unexpected behavior.",
    "Measure": "Analysis of compliance to style guides of the source code ensures that source code formatting rules are met (e.g. indentation, loops, ...).",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Usage of multiple analyzers",
    "Level": "4",
    "Description": "Usage of multiple analyzers involves employing various static and dynamic analysis tools to comprehensively evaluate the codebase for vulnerabilities, code quality, and adherence to best practices. This multi-tool approach ensures thorough coverage and reduces the likelihood of missing critical issues. Tools like SonarQube, ESLint, and PMD can be integrated into DevSecOps pipelines to provide diverse analysis capabilities and enhance overall security and quality.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Performs comprehensive static code analysis for code quality and security vulnerabilities, integrating seamlessly with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "ESLint",
        "Description": "Analyzes JavaScript code for stylistic and security issues, easily integrated into CI/CD workflows for continuous code quality monitoring.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "PMD",
        "Description": "Detects code quality issues and potential vulnerabilities in various programming languages, compatible with CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "C++", "Python"]
      }
    ],
    "Risk": "Each vulnerability analyzer has different opportunities. By using just one analyzer, some vulnerabilities might not be found.",
    "Measure": "Usage of multiple static tools to find more vulnerabilities.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "High",
    "Usefulness": "Low",
    "SAMM": "V-ST-3-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test for image lifetime",
    "Level": "2",
    "Description": "Testing for image lifetime involves ensuring that infrastructure images (e.g., container images) are updated and maintained within their valid lifespans to prevent security vulnerabilities and ensure compatibility. This practice helps in maintaining a secure and efficient infrastructure by avoiding the use of outdated or unsupported images. Tools like Trivy, Clair, and Docker Hub can be integrated into DevSecOps pipelines to automate the monitoring and management of image lifetimes.",
    "Tools": [
      {
        "Name": "Trivy",
        "Description": "A vulnerability scanner that can assess container image lifetimes and ensure images are up-to-date within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Clair",
        "Description": "An open-source vulnerability scanner for container images that can monitor and enforce image lifetimes within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Docker Hub",
        "Description": "Provides image repository services with automated image updates and lifecycle management, compatible with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Old container images in production indicate that patch management is not performed and therefore vulnerabilities might exists.",
    "Measure": "Check the image age of containers in production.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Medium",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test for new image version",
    "Level": "3",
    "Description": "Testing for new image versions involves verifying that updated infrastructure images comply with security policies and perform as expected before deployment. This ensures that new image versions do not introduce vulnerabilities or degrade system performance. Tools like Docker Compose, Kubernetes, and Jenkins can be integrated into DevSecOps pipelines to automate the testing and validation of new image versions.",
    "Tools": [
      {
        "Name": "Docker Compose",
        "Description": "Defines and runs multi-container Docker applications, facilitating the testing of new image versions within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "Manages containerized applications and can automate the testing of new image versions within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jenkins",
        "Description": "Automates the deployment and testing of new image versions within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "When a new version of an image is available, it might fix security vulnerabilities.",
    "Measure": "Check for new images of containers in production.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "Medium",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.2.1",
    "ISO 27001:2022": "8.8,8.7,8.27"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Defined deployment process",
    "Level": "1",
    "Description": "Defining a deployment process ensures that there are established criteria in terms of functionalities, security, compliance, and performance, and that the artifacts meet them. This structured approach reduces the risk of deploying insecure or malfunctioning artifacts.",
    "Tools": [],
    "Risk": "Deployment of insecure or malfunctioning artifacts.",
    "Measure": "Defining a deployment process ensures that there are established criteria in terms of functionalities, security, compliance, and performance, and that the artifacts meet them.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-1-A",
    "ISO 27001:2017": "14.2.2",
    "ISO 27001:2022": "5.37,8.32"
  },
  {
    "Dimension": "Culture and Organization",
    "Sub Dimension": "Process",
    "Activity": "Definition of a change management process",
    "Level": "3",
    "Description": "Defining a change management process involves establishing structured procedures for requesting, reviewing, approving, and implementing changes to the infrastructure and applications. This ensures that changes are made systematically, reducing the risk of introducing vulnerabilities or disruptions. Pipeline-compatible tools like Jira, ServiceNow, and GitLab can automate aspects of the change management process within CI/CD pipelines.",
    "Tools": [],
    "Risk": "The impact of a change is not controlled because these are not recorded or documented.",
    "Measure": "Each change of a system is automatically recorded and adequately logged.",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "",
    "ISO 27001:2017": "11/30/2002",
    "ISO 27001:2022": "8.32,8.15"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Automated deployment of automated PRs",
    "Level": "3",
    "Description": "Once automated pull requests for patching dependencies are merged, the deployment of these updates is automated to ensure that patched artifacts are deployed without manual intervention. This ensures that vulnerabilities are patched in production environments quickly. Pipeline-compatible tools like Jenkins, GitLab CI/CD, and GitHub Actions can facilitate automated deployments.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that enables continuous integration and continuous delivery (CI/CD) pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "A part of GitLab that provides continuous integration and deployment pipelines for automating the build, test, and deployment processes.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitHub Actions",
        "Description": "A CI/CD tool integrated into GitHub repositories that allows automation of workflows for building, testing, and deploying code.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Even if automated dependencies PRs are merged, they might not be deployed. This results in vulnerabilities in running artifacts stay for too long and might get exploited.",
    "Measure": "After merging of an automated dependency PR, automated deployment is needed,",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "O-EM-2-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Automated merge of automated PRs",
    "Level": "2",
    "Description": "Automated merging of pull requests for dependency updates ensures that patched dependencies are integrated into the codebase without manual intervention, provided they pass automated tests. This accelerates the patching process and reduces the risk of human error. Pipeline-compatible tools like Dependabot and Renovate often have built-in support for automatic merging of approved PRs.",
    "Tools": [
      {
        "Name": "Dependabot",
        "Description": "A GitHub service that automatically scans and updates dependencies to their secure and latest versions.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Renovate",
        "Description": "An open-source tool that automates dependency updates and ensures that all dependencies are pinned to specific versions.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities in running artifacts stay for too long and might get exploited.",
    "Measure": "A good practice is to merge trusted dependencies (e.g. spring boot) after a grace period like one week. Often, patches, fixes and minor updates are automatically merged. Be aware that automated merging requires a high automated test coverage. Enforcement of merging of pull requests after a grace period.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "O-EM-2-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Nightly build of images (base images)",
    "Level": "2",
    "Description": "Regularly rebuilding base images on a nightly basis ensures that any updates or patches to underlying packages are incorporated, reducing the risk of vulnerabilities in running containers. This automated process helps maintain up-to-date and secure base images. Pipeline-compatible tools like Jenkins, GitHub Actions, and GitLab CI/CD can schedule and automate nightly builds.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that enables continuous integration and continuous delivery (CI/CD) pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitHub Actions",
        "Description": "A CI/CD tool integrated into GitHub repositories that allows automation of workflows for building, testing, and deploying code.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "A part of GitLab that provides continuous integration and deployment pipelines for automating the build, test, and deployment processes.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities in running containers stay for too long and might get exploited.",
    "Measure": "Custom base images are getting build at least nightly. In case the packages in the base image e.g. <i>centos</i> has changed, the build server triggers the build of depending images.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "O-EM-1-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Usage of a maximum lifetime for images",
    "Level": "2",
    "Description": "Setting a maximum lifetime for container images ensures that images are periodically updated, reducing the risk of long-running containers with unpatched vulnerabilities. This practice mitigates the risk of memory leaks and simplifies recovery from compromised containers by enforcing regular restarts or redeployments. Pipeline-compatible tools like Kubernetes and Docker can enforce image lifetimes and facilitate scheduled deployments.",
    "Tools": [
      {
        "Name": "Kubernetes",
        "Description": "An open-source container orchestration system for automating application deployment, scaling, and management.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Docker",
        "Description": "A platform for developing, shipping, and running applications in containers, ensuring consistency across environments.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities in images of running containers stay for too long and might get exploited. Long running containers have potential memory leaks. A compromised container might get killed by restarting the container (e.g. in case the attacker has not reached the persistence layer).",
    "Measure": "A short maximum lifetime for images is defined, e.g. 30 days. The project images, based on the nightly builded images, are deployed at least once within the defined lifetime. Third Party images are deployed at least once within the defined lifetime.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Patch Management",
    "Activity": "Usage of a short maximum lifetime for images",
    "Level": "4",
    "Description": "Implementing a short maximum lifetime for container images, such as deploying images daily or just-in-time when a new component is available, ensures that containers are frequently refreshed with the latest patches and updates. This practice minimizes the window for potential vulnerabilities to be exploited. Pipeline-compatible tools like Jenkins, GitLab CI/CD, and Kubernetes can automate the frequent build and deployment processes.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that enables continuous integration and continuous delivery (CI/CD) pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "A part of GitLab that provides continuous integration and deployment pipelines for automating the build, test, and deployment processes.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "An open-source container orchestration system for automating application deployment, scaling, and management.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities in running containers stay for too long and might get exploited.",
    "Measure": "A good practice is to perform the build and deployment daily or even just-in-time, when a new component (e.g. package) for the image is available.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "O-EM-2-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for infrastructure",
    "Activity": "Test for unauthorized installation",
    "Level": "3",
    "Description": "Testing for unauthorized installation involves verifying that no unauthorized software or applications are installed within the infrastructure. This ensures that only approved and secure applications are running, reducing the risk of malicious software compromising the system. Tools like Tripwire, OSSEC, and Sysdig can be integrated into DevSecOps pipelines to automate the detection and prevention of unauthorized installations.",
    "Tools": [
      {
        "Name": "Tripwire",
        "Description": "Monitors and detects unauthorized changes to system files and configurations, integrated into CI/CD pipelines for continuous security.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OSSEC",
        "Description": "An open-source host-based intrusion detection system that detects unauthorized installations and changes, compatible with CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Sysdig",
        "Description": "Provides runtime security and monitoring to detect unauthorized installations and activities within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Unapproved components are used.",
    "Measure": "Components must be whitelisted. Regular scans on the docker infrastructure (e.g. cluster) need to be performed, to verify that only standardized base images are used.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "",
    "ISO 27001:2017": "12.5.1",
    "ISO 27001:2022": "8.19,8.8"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Defined decommissioning process",
    "Level": "2",
    "Description": "A clear decommissioning process ensures the removal of unused applications from the `Inventory of production components` and, if implemented, from the `Inventory of production artifacts`. This reduces the risk of vulnerabilities in unused applications being exploited by attackers.",
    "Tools": [
      {
        "Name": "ServiceNow",
        "Description": "A platform that provides IT service management and automates the decommissioning of services and assets.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "CMDB",
        "Description": "Configuration Management Database tools like BMC Helix or Device42 help maintain inventories and manage decommissioning processes.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Unused applications are not maintained and may contain vulnerabilities. Once exploited, they can be used to attack other applications or to perform lateral movements within the organization.",
    "Measure": "A clear decommissioning process ensures the removal of unused applications from the `Inventory of production components` and if implemented from `Inventory of production artifacts`.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "O-OM-2-B",
    "ISO 27001:2017": "11/1/2007, 12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "7.14"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Inventory of production artifacts",
    "Level": "2",
    "Description": "A documented inventory of artifacts in production, such as container images, exists and is maintained either manually or automatically. This ensures that in case a vulnerability of high or critical severity exists, it is known where the affected artifacts are deployed.",
    "Tools": [
      {
        "Name": "Anchore",
        "Description": "An open-source container image inspection and analysis tool that helps maintain an inventory of production artifacts.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Clair",
        "Description": "An open-source project for the static analysis of vulnerabilities in application containers.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Artifact",
        "Description": "A service that provides on-demand access to AWS compliance reports and select online agreements.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "In case a vulnerability of severity high or critical exists, it is challenging to identify where an artifact (e.g., container image) with that vulnerability is deployed.",
    "Measure": "A documented inventory of artifacts in production like container images exists (gathered manually or automatically).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "High",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-SD-2-A",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "5.9,5.12"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Inventory of production components",
    "Level": "1",
    "Description": "Maintaining an inventory of production components involves tracking and managing all software and hardware elements deployed in the production environment. This ensures visibility, facilitates maintenance, and aids in compliance and auditing processes. Pipeline-compatible tools such as Ansible, Puppet, Terraform, and AWS Config can automate the inventory management within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Ansible",
        "Description": "Automation tool that can manage and maintain an inventory of production components through playbooks integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["YAML"]
      },
      {
        "Name": "Puppet",
        "Description": "Configuration management tool that automates the inventory and management of production components within deployment pipelines.",
        "Opensource": true,
        "Languages": ["Ruby"]
      },
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code tool that can provision and manage production components, maintaining an up-to-date inventory integrated into CI/CD workflows.",
        "Opensource": true,
        "Languages": ["HCL"]
      },
      {
        "Name": "AWS Config",
        "Description": "Service that enables assessment, auditing, and evaluation of the configurations of AWS resources, maintaining an inventory of production components.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "An organization is unaware of components like applications in production. Not knowing existing applications in production leads to not assessing it.",
    "Measure": "A documented inventory of components in production exists (gathered manually or automatically). For example a manually created document with applications in production. In a kubernetes cluster, namespaces can be automatically gathered and documented, e.g. in a JSON in a S3 bucket/git repository, dependency track.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-A",
    "ISO 27001:2017": "",
    "ISO 27001:2022": "5.9,5.12"
  },
  {
    "Dimension": "Build and Deployment",
    "Sub Dimension": "Deployment",
    "Activity": "Inventory of production dependencies",
    "Level": "3",
    "Description": "Maintaining an inventory of production dependencies involves tracking all third-party libraries, frameworks, and services that applications depend on in the production environment. This ensures that dependencies are up-to-date, secure, and compliant with organizational standards. Pipeline-compatible tools such as Dependabot, Renovate, and Snyk can automate the monitoring and management of production dependencies within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Dependabot",
        "Description": "GitHub-integrated tool that automatically creates pull requests to update dependencies, ensuring the production environment uses secure and up-to-date libraries.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Renovate",
        "Description": "Automated tool that manages and updates dependencies across various languages and platforms, integrated into CI/CD pipelines for continuous dependency management.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that scans for vulnerabilities in dependencies and monitors library health within CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Delayed identification of components and their vulnerabilities in production. In case a vulnerability is known by the organization, it needs to be known where an artifacts with that vulnerability is deployed with which dependencies.",
    "Measure": "A documented inventory of dependencies used in artifacts like container images and containers exists.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "High",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-SD-2-A",
    "ISO 27001:2017": "",
    "ISO 27001:2022": "5.9,5.12"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Test KPI",
    "Activity": "Generation of response statistics",
    "Level": "3",
    "Description": "Generating response statistics involves collecting and analyzing data related to security incident responses to evaluate the effectiveness and efficiency of the incident management process. Pipeline-compatible tools like Prometheus and Grafana can automate the collection and visualization of response metrics within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "Open-source monitoring system and time series database that can collect response metrics for analysis.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "Open-source platform for creating dashboards and visualizing response statistics collected by Prometheus.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "No or delayed reaction to findings leads to potential exploitation of findings.",
    "Measure": "Creation and response statistics (e.g. Mean Time to Resolution) of findings. This is also referred to as _Mean Time to Resolve_.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Advanced visualization of defects",
    "Level": "4",
    "Description": "Advanced visualization of defects involves creating detailed and interactive dashboards that display defect metrics, trends, and patterns to provide deeper insights into the quality and security of the software. Pipeline-compatible tools like SonarQube, Jira, and Grafana can automate the aggregation and visualization of defect data within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that aggregates defect data and provides advanced visualization through dashboards.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Jira",
        "Description": "Project management tool that can integrate with SonarQube to visualize defect trends and metrics.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "Open-source platform for creating detailed dashboards that visualize defect data from various sources.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Correlation of the vulnerabilities of different tools to have an overview of the the overall security level per component/project/team is not given.",
    "Measure": "Findings are visualized per component/project/team.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Very High",
    "Usefulness": "Medium",
    "SAMM": "I-DM-3-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.12,5.13,5.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Fix based on severity",
    "Level": "1",
    "Description": "Fixing defects based on severity involves prioritizing and addressing defects according to their impact and criticality. High-severity defects are resolved promptly to mitigate significant risks, while lower-severity issues are scheduled accordingly. Pipeline-compatible tools like Jira, GitLab, and SonarQube can automate the prioritization and tracking of defect fixes within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Project management tool that can track and prioritize defects based on severity levels.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab",
        "Description": "Integrated CI/CD tool that can manage and automate the prioritization of defect fixes based on severity.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that categorizes defects by severity and integrates with CI/CD pipelines for automated tracking.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Overwhelming volume of security findings from automated testing tools. This might lead to ignorance of findings.",
    "Measure": "Implement a very simple risk-based prioritization framework for vulnerability remediation based on the severity of the findings. On level one, fix only critical findings.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-DM-3-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.12,5.13,5.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Reproducible defect tickets",
    "Level": "4",
    "Description": "Creating reproducible defect tickets involves documenting defects in a manner that allows developers to consistently replicate and understand the issues. This ensures efficient resolution and prevents recurrence. Pipeline-compatible tools like Jira, GitHub Issues, and GitLab Issues can automate the creation and management of reproducible defect tickets within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Project management tool that can automate the creation and tracking of reproducible defect tickets.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitHub Issues",
        "Description": "Issue tracking system integrated with GitHub repositories for managing reproducible defect reports.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab Issues",
        "Description": "Issue tracking feature within GitLab for managing and automating reproducible defect tickets.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerability descriptions are hard to understand by staff from operations and development.",
    "Measure": "Vulnerabilities include the test procedure to give the staff from operations and development the ability to reproduce vulnerabilities. This enhances the understanding of vulnerabilities and therefore the fix have a higher quality.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.12,5.13,5.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Simple visualization of defects",
    "Level": "2",
    "Description": "Simple visualization of defects involves creating basic charts and graphs to display defect metrics, such as defect count over time or defect distribution by category. This provides a straightforward overview of the defect landscape. Pipeline-compatible tools like SonarQube and Grafana can automate the generation of simple defect visualizations within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that provides basic visualizations of defect metrics through dashboards.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "Open-source platform for creating simple charts and graphs to visualize defect data from various sources.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "The security level of a component is not visible. Therefore, the motivation to enhance the security is not give.",
    "Measure": "Vulnerabilities are simple visualized.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-DM-1-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.12,5.13,5.1"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Fix based on accessibility",
    "Level": "3",
    "Description": "Fixing defects based on accessibility involves prioritizing and addressing defects that impact the accessibility of the application, ensuring it is usable by individuals with disabilities. This enhances the user experience and ensures compliance with accessibility standards. Pipeline-compatible tools like Axe, Lighthouse, and SonarQube can automate the detection and tracking of accessibility-related defects within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Axe",
        "Description": "Accessibility testing tool that can be integrated into CI/CD pipelines to detect and fix accessibility issues.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Lighthouse",
        "Description": "Automated tool for improving the quality of web pages, including accessibility audits within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that can categorize and track accessibility-related defects within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Overwhelming volume of security findings from automated testing tools. This might lead to ignorance of findings.",
    "Measure": "Implement a simple risk-based prioritization framework for vulnerability remediation based on accessibility of the applications.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-DM-3-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25,5.12,5.13,5.1"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Production near environments are used by developers",
    "Level": "4",
    "Description": "Using production-like environments for development involves creating environments that closely mirror the production setup to ensure that applications behave consistently across development and production stages. This practice enhances the reliability and security of deployments by identifying issues early. Pipeline-compatible tools like Docker, Kubernetes, and Terraform can automate the provisioning and management of production-like environments within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Docker",
        "Description": "Platform for developing, shipping, and running applications in containers, enabling production-like environment setups within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "Container orchestration system that manages production-like environments by deploying and scaling containerized applications within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code tool that can automate the provisioning of production-like environments within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["HCL"]
      }
    ],
    "Risk": "In case an errors occurs in production, the developer need to be able to create a production near environment on a local development environment.",
    "Measure": "Usage of infrastructure as code helps to create a production near environment. The developer needs to be trained in order to setup a local development environment. In addition, it should be possible to create production like test data. Often personal identifiable information is anonymized in order to comply with data protection laws.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "11/30/2004",
    "ISO 27001:2022": "8.31,8.14"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of test and production environments",
    "Level": "2",
    "Description": "Usage of test and production environments involves segregating environments to ensure that testing activities do not impact production systems. This separation enhances security and stability by isolating development and testing processes from live operations. Tools like Terraform, Ansible, and Kubernetes can be integrated into DevSecOps pipelines to manage and enforce environment segregation.",
    "Tools": [
      {
        "Name": "Terraform",
        "Description": "Infrastructure as Code (IaC) tool that manages the provisioning and segregation of test and production environments within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "Automation tool used for configuration management and enforcing environment segregation, compatible with CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kubernetes",
        "Description": "Manages containerized applications and can enforce environment segregation within CI/CD pipelines for secure deployments.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Security tests are not running regularly because test environments are missing",
    "Measure": "A test and a production like environment is used",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "11/30/2004",
    "ISO 27001:2022": "Not explicitly covered by ISO 27001 - too specific,8.31,8.14"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Usage of a vulnerability management system",
    "Level": "3",
    "Description": "Usage of a vulnerability management system involves implementing tools that continuously identify, assess, and remediate vulnerabilities within the application and infrastructure. This proactive approach ensures ongoing security and compliance by managing vulnerabilities throughout the software development lifecycle. Tools like Qualys, Nessus, and Snyk can be integrated into DevSecOps pipelines to automate vulnerability scanning and management processes.",
    "Tools": [
      {
        "Name": "Qualys",
        "Description": "Provides comprehensive vulnerability management and continuous monitoring, integrated into CI/CD pipelines for automated security assessments.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Nessus",
        "Description": "Offers advanced vulnerability scanning and management capabilities, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Automates vulnerability scanning and remediation for dependencies and container images, seamlessly integrating with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Maintenance of false positives in each tool enforces a high workload. In addition a correlation of the same finding from different tools is not possible.",
    "Measure": "Aggregation of vulnerabilities in one tool reduce the workload to handle them, e.g. mark as false positives.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "Medium",
    "SAMM": "I-DM-1-B",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,6.8,5.25,5.26,5.27"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Alerting",
    "Level": "2",
    "Description": "Alerting involves setting up notifications for specific events or thresholds to ensure timely responses to potential issues or security incidents. This enhances the ability to detect and address problems proactively. Tools like Prometheus, Grafana, and PagerDuty can be integrated into DevSecOps pipelines to automate alerting based on predefined metrics and conditions.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that collects metrics and triggers alerts based on predefined rules within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that can be configured to send alerts based on dashboard metrics, integrated into DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "PagerDuty",
        "Description": "An incident response platform that manages and routes alerts to appropriate teams, compatible with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Incidents are discovered after they happened.",
    "Measure": "Thresholds for metrics are set. In case the thresholds are reached, alarms are send out. Which should get attention due to the critically.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "",
    "Time": "",
    "Usefulness": "",
    "SAMM": "I-DM-A 3",
    "ISO 27001:2017": "11/30/2004",
    "ISO 27001:2022": "6.8,5.25,8.31"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Test KPI",
    "Activity": "Patching mean time to resolution via production",
    "Level": "4",
    "Description": "Measuring and communicating the Mean Time to Resolution (MTTR) related to patching helps identify delays in the patching process. Unaddressed vulnerabilities can be exploited by attackers, leading to potential security breaches and data loss.",
    "Tools": [
      {
        "Name": "Datadog",
        "Description": "A monitoring and analytics platform that can track MTTR metrics across various services.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Prometheus",
        "Description": "An open-source systems monitoring and alerting toolkit, useful for tracking MTTR.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "An open-source platform for monitoring and observability, enabling visualization of MTTR metrics.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Without measuring Mean Time to Resolution (MTTR) related to patching, it is challenging to identify delays in the patching process. Unaddressed vulnerabilities can be exploited by attackers, leading to potential security breaches and data loss.",
    "Measure": "Measurement and communication of the time from the availability of a patch to its deployment in production in alignment with Service Level Agreements (SLAs), conducted at least on a quarterly basis. Average time to patch is visualized per component/project/team.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Medium",
    "Time": "Low",
    "Usefulness": "High",
    "SAMM": "I-DM-3-B",
    "ISO 27001:2017": "16.1.4",
    "ISO 27001:2022": "5.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Treatment of all defects",
    "Level": "5",
    "Description": "Treatment of all defects involves identifying, prioritizing, and addressing every defect detected during testing to ensure the highest quality and security of the software. This comprehensive approach ensures that no issues are left unresolved, thereby enhancing the reliability and integrity of the application. Tools like Jira, Bugzilla, and GitLab Issues can be integrated into DevSecOps pipelines to manage and track defect resolution effectively.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "A project management tool that tracks and manages defects throughout the development lifecycle, integrated with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Bugzilla",
        "Description": "An open-source bug tracking system that manages defect reporting and resolution within DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab Issues",
        "Description": "Integrated issue tracking within GitLab that manages and resolves defects as part of the CI/CD process.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities with severity low are not visible.",
    "Measure": "All vulnerabilities are added to the quality gate.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "Very High",
    "Usefulness": "Medium",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,5.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Treatment of defects with severity high or higher",
    "Level": "1",
    "Description": "Treatment of defects with high severity or higher focuses on addressing critical and major issues that pose significant risks to the application\u2019s functionality and security. This prioritization ensures that the most impactful defects are resolved promptly to maintain system integrity. Tools like Jira, GitLab Issues, and Bugzilla can be configured to prioritize and manage high-severity defects within DevSecOps pipelines, ensuring timely resolution.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Allows prioritization and management of high-severity defects, ensuring they are addressed promptly within CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab Issues",
        "Description": "Enables tagging and prioritization of high-severity defects, integrated with CI/CD pipelines for efficient resolution.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Bugzilla",
        "Description": "Supports categorization and prioritization of high-severity defects, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities with severity high or higher are not visible.",
    "Measure": "Vulnerabilities with severity high or higher are added to the quality gate.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,5.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Consolidation",
    "Activity": "Treatment of defects with severity middle",
    "Level": "3",
    "Description": "Treatment of defects with middle severity involves addressing issues that have a moderate impact on the application\u2019s functionality and security. This ensures that the application maintains a balanced level of quality while prioritizing critical issues. Tools like Jira, GitLab Issues, and Bugzilla can be utilized to manage and track the resolution of middle-severity defects within DevSecOps pipelines, ensuring systematic and timely fixes.",
    "Tools": [
      {
        "Name": "Jira",
        "Description": "Manages and tracks the resolution of middle-severity defects, ensuring systematic handling within CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "GitLab Issues",
        "Description": "Enables tracking and management of middle-severity defects, integrated with CI/CD pipelines for efficient resolution.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Bugzilla",
        "Description": "Supports management and tracking of middle-severity defects, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities with severity middle are not visible.",
    "Measure": "Vulnerabilities with severity middle are added to the quality gate.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "I-DM-2-B",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,5.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Application tests",
    "Activity": "High coverage of security related module and integration tests",
    "Level": "5",
    "Description": "Ensuring high coverage of security-related module and integration tests involves thoroughly testing security functionalities and their interactions within the application. This practice helps in identifying and mitigating security vulnerabilities early in the development process. Pipeline-compatible tools like Selenium, OWASP ZAP, and SonarQube can automate security module and integration tests within CI/CD pipelines, ensuring comprehensive test coverage.",
    "Tools": [
      {
        "Name": "Selenium",
        "Description": "Automation tool for testing web applications, including security-related functionalities within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "Python", "C#"]
      },
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can perform automated security module and integration tests within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for security vulnerabilities and integrates security module tests within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities are rising due to code changes in a complex microservice environment in not important components.",
    "Measure": "Implementation of security related tests via unit tests and integration tests. Including the test of libraries, in case the are not tested already.",
    "Knowledge": "",
    "Resources": "High",
    "Time": "",
    "Usefulness": "High",
    "SAMM": "V-ST-3-B",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Application tests",
    "Activity": "Security integration tests for important components",
    "Level": "3",
    "Description": "Conducting security integration tests for important components involves testing the security aspects of key application modules and their interactions to ensure they function securely together. This practice helps in identifying and addressing vulnerabilities that may arise from component integrations. Pipeline-compatible tools like OWASP ZAP, Selenium, and SonarQube can automate security integration tests within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "OWASP ZAP",
        "Description": "Open-source web application security scanner that can perform security integration tests on key components within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Selenium",
        "Description": "Automation tool for testing web applications, including security integration tests for important components within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "Python", "C#"]
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for security vulnerabilities and integrates security integration tests within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities are rising due to code changes in a complex microservice environment.",
    "Measure": "Implementation of essential security related integration tests. For example for authentication and authorization.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "Medium",
    "SAMM": "V-ST-3-B",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Application tests",
    "Activity": "Security unit tests for important components",
    "Level": "2",
    "Description": "Conducting security unit tests for important components involves testing individual units or functions of the application for security vulnerabilities. This ensures that each component adheres to security best practices and functions securely in isolation. Pipeline-compatible tools like Jest (with security plugins), SonarQube, and Snyk can automate security unit tests within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Jest",
        "Description": "JavaScript testing framework that can be extended with security plugins to perform security unit tests within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for security vulnerabilities and integrates security unit tests within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that scans dependencies for vulnerabilities and can integrate security unit tests within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Vulnerabilities are rising due to code changes.",
    "Measure": "Usage of unit tests to test important security related features like authentication and authorization.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "V-ST-3-B",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Application tests",
    "Activity": "Smoke Test",
    "Level": "4",
    "Description": "Conducting smoke tests involves performing basic checks to ensure that the most critical functionalities of the application are working as expected after a deployment. This helps in quickly identifying major issues before proceeding with more extensive testing. Pipeline-compatible tools like Selenium, Cypress, and Jenkins can automate smoke tests within CI/CD pipelines, ensuring rapid validation of deployments.",
    "Tools": [
      {
        "Name": "Selenium",
        "Description": "Automation tool for testing web applications, suitable for implementing smoke tests within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "Python", "C#"]
      },
      {
        "Name": "Cypress",
        "Description": "End-to-end testing framework that can automate smoke tests for web applications within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "Jenkins",
        "Description": "Automation server that can orchestrate and run smoke tests as part of the CI/CD pipeline.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "During a deployment an error might happen which leads to non-availability of the system, a part of the system or a feature.",
    "Measure": "Integration tests are performed against the production environment after each deployment.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "V-ST-3-B",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Test-Intensity",
    "Activity": "Creation and application of a testing concept",
    "Level": "4",
    "Description": "Creation and application of a testing concept involves defining a comprehensive testing strategy that aligns with the project's objectives and ensures quality and security throughout the software development lifecycle. This includes selecting appropriate testing methodologies, defining test cases, and integrating them into the DevSecOps pipeline. Tools like Jenkins, GitLab CI/CD, and CircleCI facilitate the automation and integration of testing processes into CI/CD workflows.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "An open-source automation server that facilitates CI/CD pipeline integration, allowing automated execution of testing scripts and processes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Integrated part of GitLab that provides robust CI/CD pipeline capabilities, enabling automated testing and deployment processes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "CircleCI",
        "Description": "A CI/CD platform that automates testing and deployment, supporting seamless integration with various development tools.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Scans might use a too small or too high test intensity.",
    "Measure": "A testing concept considering the amount of time per scan/intensity is created and applied. A dynamic analysis needs more time than a static analysis. The dynamic scan, depending on the test intensity might be performed on every commit, every night, every week or once in a month.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "High",
    "Usefulness": "Medium",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.25,8.32,8.27,8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Test-Intensity",
    "Activity": "Deactivating of unneeded tests",
    "Level": "3",
    "Description": "Deactivating unneeded tests involves identifying and disabling tests that are redundant, obsolete, or no longer relevant to the current development context. This optimizes the testing process by reducing execution time and resource consumption. Tools like Jenkins and GitLab CI/CD can be configured to selectively run tests based on changes in the codebase, ensuring only necessary tests are executed.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Allows configuration of conditional test execution within CI/CD pipelines to optimize testing processes.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Provides features to define and manage which tests to run based on pipeline configurations and code changes.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "As tools cover a wide range of different vulnerability tests, they might not match the used components. Therefore, they need more time and resources as they need and the feedback loops takes too much time.",
    "Measure": "Unneeded tests are deactivated. For example in case the service is using a Mongo database and no mysql database, the dynamic scan doesn't need to test for sql injections.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "Low",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Test-Intensity",
    "Activity": "Default settings for intensity",
    "Level": "1",
    "Description": "Default settings for test intensity refer to the baseline configuration of test execution frequency and scope without any optimizations. This ensures that all standard tests are executed uniformly across the pipeline. While not optimized for specific project needs, default settings provide a consistent testing foundation. Pipeline-compatible tools like Jenkins, GitLab CI/CD, and CircleCI use default test configurations out-of-the-box.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Executes predefined test suites with default configurations in CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Runs default test suites as part of the CI/CD process without additional configurations.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "CircleCI",
        "Description": "Automatically runs standard test suites with default settings in CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Time pressure and ignorance might lead to false predictions for the test intensity.",
    "Measure": "The intensity of the used tools are not modified to safe time.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Low",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25,8.27"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Test-Intensity",
    "Activity": "High test intensity",
    "Level": "1",
    "Description": "High test intensity involves executing an extensive suite of tests, including unit, integration, system, and security tests, to ensure comprehensive coverage and early detection of issues. This approach enhances the reliability and security of the software but may increase pipeline execution time. Tools like Jenkins, GitLab CI/CD, and CircleCI can manage high-intensity test suites by leveraging parallel execution and optimized resource allocation.",
    "Tools": [
      {
        "Name": "Jenkins",
        "Description": "Supports parallel test execution and resource optimization to handle high-intensity test suites.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "GitLab CI/CD",
        "Description": "Facilitates high-intensity testing by allowing parallel jobs and efficient pipeline configurations.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "CircleCI",
        "Description": "Enables high-intensity testing through concurrent job executions and scalable pipeline resources.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "A too small intensity or a too high confidence might lead to not visible vulnerabilities.",
    "Measure": "A deep scan with high test intensity and a low confidence threshold is performed.",
    "Knowledge": "High (two disciplines)",
    "Resources": "",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25,8.27"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Defense metrics",
    "Level": "4",
    "Description": "Defense metrics involve tracking and analyzing security-related metrics to assess the effectiveness of defense mechanisms and strategies. This includes metrics like detection rates, response times, and incident counts. Tools like Prometheus, Grafana, and Splunk can be integrated into DevSecOps pipelines to automate the collection and visualization of defense metrics, enabling continuous improvement of security measures.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that collects and stores metrics, integrated into CI/CD pipelines for defense metric tracking.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that creates dashboards for monitoring defense metrics, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "Provides comprehensive monitoring and visualization capabilities for defense metrics within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "IDS/IPS systems like packet- or application-firewalls detect and prevent attacks. It is not known how many attacks has been detected and blocked.",
    "Measure": "Gathering of defense metrics like TCP/UDP sources enables to assume the geographic location of the request. Assuming a Kubernetes cluster with an egress-traffic filter (e.g. IP/domain based), an alert might be send out in case of every violation. For ingress-traffic, alerting might not even be considered.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "",
    "Usefulness": "Very High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "8.15,8.2"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Audit of system events",
    "Level": "3",
    "Description": "Auditing system events involves recording and reviewing logs and activities within the infrastructure to detect and investigate security incidents. This ensures accountability, compliance, and timely identification of suspicious activities. Pipeline-compatible tools like ELK Stack, Splunk, and Graylog can automate the collection and analysis of system event audits within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "ELK Stack (Elasticsearch, Logstash, Kibana)",
        "Description": "Comprehensive logging and monitoring solution for collecting, searching, and visualizing system event audits.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "Platform for searching, monitoring, and analyzing machine-generated data, including system event logs.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Graylog",
        "Description": "Open-source log management platform with advanced log analysis and visualization capabilities for auditing system events.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "System events (system calls) trends and attacks are not detected.",
    "Measure": "Gathering of system calls.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Exploit likelihood estimation",
    "Level": "3",
    "Description": "Estimating exploit likelihood involves assessing the probability that identified vulnerabilities can be exploited by attackers. This helps prioritize remediation efforts based on risk levels. Pipeline-compatible tools like Snyk, SonarQube, and OWASP Dependency-Check can automate the estimation of exploit likelihood within CI/CD pipelines by analyzing vulnerabilities and their potential impact.",
    "Tools": [
      {
        "Name": "Snyk",
        "Description": "Developer-first security tool that finds and fixes vulnerabilities in dependencies and estimates their exploit likelihood.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "SonarQube",
        "Description": "Continuous inspection tool that analyzes code for vulnerabilities and estimates the likelihood of their exploitation.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "OWASP Dependency-Check",
        "Description": "Software composition analysis tool that identifies vulnerabilities in project dependencies and assesses their exploit likelihood.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Without proper prioritization, organizations may waste time and effort on low-risk vulnerabilities while neglecting critical ones.",
    "Measure": "Estimate the likelihood of exploitation by using data (CISA KEV) from the past or prediction models (EPSS).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Backup",
    "Level": "2",
    "Description": "Implementing backups involves creating copies of critical data and system configurations to ensure recovery in case of data loss, corruption, or disasters. This practice enhances data resilience and business continuity. Pipeline-compatible tools like Veeam, AWS Backup, and Azure Backup can automate backup processes within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Veeam",
        "Description": "Backup and recovery solution that automates data protection and ensures business continuity.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "AWS Backup",
        "Description": "Managed backup service that centralizes and automates data protection across AWS services.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Backup",
        "Description": "Cloud-based backup solution that automates and manages data protection for Azure and on-premises environments.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "If errors are experienced during the deployment process you want to deploy an old release. However, due to changes in the database this is often unfeasible.",
    "Measure": "Performing automated periodical backups are used. Backup before deployment can help facilitate deployments whilst testing the backup restore processes.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "TODO",
    "ISO 27001:2017": "14.2.6",
    "ISO 27001:2022": "8.13,8.31"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Advanced app. metrics",
    "Level": "4",
    "Description": "Collecting advanced application metrics involves gathering detailed performance and security data to gain deeper insights into application behavior and health. This aids in optimizing performance, identifying bottlenecks, and detecting security anomalies. Pipeline-compatible tools like Prometheus, Grafana, and New Relic can automate the collection and visualization of advanced application metrics within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "Open-source monitoring system that collects detailed application metrics for analysis.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "Open-source platform for visualizing advanced application metrics collected by Prometheus and other monitoring tools.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "New Relic",
        "Description": "Application performance monitoring tool that offers comprehensive metrics and insights for advanced application monitoring.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "People are not looking into tests results. Vulnerabilities not recolonized, even they are detected by tools.",
    "Measure": "All defects from the dimension Test- and Verification are instrumented.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of an security account",
    "Level": "2",
    "Description": "Using a dedicated security account for security auditing and administrative tasks ensures that critical security operations are isolated from regular infrastructure and application accounts. This separation reduces the risk of unauthorized access and limits the potential impact of compromised accounts by restricting permissions to only necessary security-related activities.",
    "Tools": [
      {
        "Name": "HashiCorp Vault",
        "Description": "A tool for securely accessing secrets, managing sensitive data, and controlling access through dedicated security accounts.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS IAM (Identity and Access Management)",
        "Description": "Provides fine-grained access control for AWS resources, enabling the creation of dedicated security accounts with specific permissions.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Active Directory",
        "Description": "Manages user identities and access privileges in Azure, allowing the creation of dedicated security accounts for administration.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Okta",
        "Description": "An identity and access management service that enables the creation and management of dedicated security accounts.",
        "Opensource": false,
        "Languages": []
      }
    ]
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of edge encryption at transit",
    "Level": "1",
    "Description": "Using encryption at the edge of traffic in transit ensures that confidential information, such as authentication factors like passwords, cannot be easily sniffed by attackers performing man-in-the-middle attacks outside the organization.",
    "Tools": [
      {
        "Name": "TLS",
        "Description": "Transport Layer Security protocol used to encrypt data in transit.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "OpenSSL",
        "Description": "A robust toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "AWS Certificate Manager",
        "Description": "A service that lets you easily provision, manage, and deploy SSL/TLS certificates for use with AWS services.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Evil actors might be able to perform a man-in-the-middle attack and sniff confidential information (e.g., authentication factors like passwords).",
    "Measure": "By using encryption at the edge of traffic in transit, it is impossible or at least harder to sniff credentials being outside of the organization.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-B",
    "ISO 27001:2017": "13.1.3, 12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.24"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of encryption at rest",
    "Level": "2",
    "Description": "Using encryption at rest ensures that data stored on physical hard disks or other storage mediums is protected. This makes it significantly harder for malicious actors to access and read sensitive information, even if they gain physical access to the storage devices.",
    "Tools": [
      {
        "Name": "AWS KMS",
        "Description": "AWS Key Management Service makes it easy to create and manage cryptographic keys and control their use across AWS services.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Storage Service Encryption",
        "Description": "Azure's service that automatically encrypts data before persisting it to Azure storage.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "VeraCrypt",
        "Description": "An open-source disk encryption software for securing data at rest.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Google Cloud Key Management",
        "Description": "Google Cloud's solution for managing cryptographic keys and ensuring encryption at rest across Google Cloud services.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "BitLocker",
        "Description": "A Microsoft Windows feature for encrypting entire volumes to protect data at rest.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "HashiCorp Vault",
        "Description": "A tool for managing secrets and encrypting data at rest with high flexibility and integration options.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "LUKS (Linux Unified Key Setup)",
        "Description": "An open-source disk encryption standard for securing data at rest on Linux systems.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Evil actors might be able to access data and read information, e.g., from physical hard disks.",
    "Measure": "By using encryption at rest, it is impossible or at least harder to read information.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.24"
  },

  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of internal encryption at transit",
    "Level": "3",
    "Description": "Using encryption internally, such as within a cluster, ensures that even if an attacker gains internal access, sniffing credentials becomes significantly more difficult. This protects against man-in-the-middle attacks within the organization's internal network.",
    "Tools": [
      {
        "Name": "Istio",
        "Description": "An open-source service mesh that provides secure service-to-service communication through mutual TLS.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Consul",
        "Description": "A tool for service networking that provides service discovery, configuration, and segmentation functionality with built-in encryption.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "OpenSSL",
        "Description": "A robust toolkit for the Transport Layer Security (TLS) and Secure Sockets Layer (SSL) protocols.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Evil actors within the organization or intercepting traffic in transit might be able to perform a man-in-the-middle attack and sniff confidential information (e.g., authentication factors like passwords).",
    "Measure": "By using encryption internally, e.g., inside of a cluster, it is impossible or at least harder to sniff credentials.",
    "Knowledge": "High (two disciplines)",
    "Resources": "High",
    "Time": "Very High",
    "Usefulness": "Very High",
    "SAMM": "I-SD-2-B",
    "ISO 27001:2017": "12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "8.24"
  },
  {
    "Dimension": "Implementation",
    "Sub Dimension": "Infrastructure Hardening",
    "Activity": "Usage of security by default for components",
    "Level": "3",
    "Description": "Implementing security by default for components, such as images, libraries, and applications, ensures that they are hardened against common vulnerabilities. This involves configuring operating systems and services with security best practices to reduce the attack surface and prevent unauthorized access.",
    "Tools": [
      {
        "Name": "Docker Bench for Security",
        "Description": "A script that checks for dozens of common best practices around deploying Docker containers in production.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Ansible",
        "Description": "An open-source automation tool that can be used to apply security hardening configurations to systems and applications.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Chef InSpec",
        "Description": "An open-source testing framework for infrastructure with a focus on compliance and security.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Components (images, libraries, applications) are not hardened, making them vulnerable to attacks and exploits.",
    "Measure": "Hardening of components is important, especially for images on which other teams rely. Hardening should be performed on the operating system and on the services inside (e.g., Nginx or a Java application).",
    "Knowledge": "Very High (three or more disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "High",
    "SAMM": "O-EM-1-A",
    "ISO 27001:2017": "Not explicitly covered by ISO 27001 - too specific, 12.6.1, 12.5.1, 11/30/2004",
    "ISO 27001:2022": "ISO 27001:2022 mapping is missing"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Dynamic depth for applications",
    "Activity": "Coverage of client side dynamic components",
    "Level": "2",
    "Description": "Ensuring coverage of client-side dynamic components involves thoroughly testing frontend elements that dynamically update based on user interactions or data changes. This enhances the reliability and security of the user interface by identifying and addressing vulnerabilities in dynamic components. Pipeline-compatible tools like Selenium, Cypress, and Jest can automate the testing of client-side dynamic components within CI/CD pipelines.",
    "Tools": [
      {
        "Name": "Selenium",
        "Description": "Automation tool for testing web applications, including client-side dynamic components within CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["Java", "Python", "C#"]
      },
      {
        "Name": "Cypress",
        "Description": "End-to-end testing framework that automates the testing of dynamic frontend components within CI/CD workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "Jest",
        "Description": "JavaScript testing framework that can be extended with security plugins to perform unit tests on dynamic frontend components.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      }
    ],
    "Risk": "Parts of the service are not covered during the scan, because JavaScript is not getting executed. Therefore, the co",
    "Measure": "Usage of a spider which executes dynamic content like JavaScript, e.g. via Selenium.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "14.2.3",
    "ISO 27001:2022": "8.32,8.29"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Correlate known vulnerabilities in infrastructure with new image versions",
    "Level": "4",
    "Description": "Correlating known vulnerabilities in infrastructure with new image versions involves mapping existing vulnerabilities to updated infrastructure images to ensure that new deployments are free from known security issues. This process enhances the security posture by preventing the introduction of vulnerable components. Tools like Clair, Anchore, and Trivy can be integrated into DevSecOps pipelines to automate vulnerability scanning and correlation with infrastructure image updates.",
    "Tools": [
      {
        "Name": "Clair",
        "Description": "An open-source vulnerability scanner for container images, integrated into CI/CD pipelines to detect and correlate vulnerabilities with image versions.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Anchore",
        "Description": "Provides comprehensive container image scanning and vulnerability assessment, seamlessly integrating with CI/CD workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Trivy",
        "Description": "A simple and comprehensive vulnerability scanner for containers and other artifacts, compatible with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "TODO.",
    "Measure": "TODO",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Very High",
    "Time": "",
    "Usefulness": "Low",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test of infrastructure components for known vulnerabilities",
    "Level": "4",
    "Description": "Testing infrastructure components for known vulnerabilities involves scanning and assessing all infrastructure elements, such as servers, databases, and networking components, to identify and remediate existing security vulnerabilities. This proactive approach ensures that infrastructure remains secure and resilient against potential threats. Tools like Nessus, OpenVAS, and Qualys can be integrated into DevSecOps pipelines to automate vulnerability scanning and remediation processes.",
    "Tools": [
      {
        "Name": "Nessus",
        "Description": "A comprehensive vulnerability scanner that identifies security vulnerabilities in infrastructure components, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OpenVAS",
        "Description": "An open-source vulnerability scanning tool that detects security issues in infrastructure components, compatible with CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Qualys",
        "Description": "Provides cloud-based vulnerability management and scanning for infrastructure components, seamlessly integrating with DevSecOps pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Infrastructure components might have vulnerabilities.",
    "Measure": "Test for known vulnerabilities in infrastructure components. Often, the only way to respond to known vulnerabilities in operating system packages is to accept the risk and wait for a patch. As the patch needs to be applied fast when it is available, this activity depends on 'Usage of a maximum life for images'.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "",
    "Usefulness": "Low",
    "SAMM": "V-ST-1-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8,8.25"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Software Composition Analysis (client side)",
    "Level": "3",
    "Description": "Software Composition Analysis (SCA) for the client side involves scanning client-side dependencies and libraries to identify and remediate known vulnerabilities and license compliance issues. This practice ensures that client applications are secure and adhere to legal requirements. Tools like Snyk, WhiteSource, and Dependabot can be integrated into DevSecOps pipelines to automate the analysis and management of client-side software components.",
    "Tools": [
      {
        "Name": "Snyk",
        "Description": "Scans client-side dependencies for vulnerabilities and license issues, integrating seamlessly with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "WhiteSource",
        "Description": "Provides comprehensive SCA for client-side libraries, automating vulnerability detection and license compliance within DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Dependabot",
        "Description": "Automates dependency updates and scans for vulnerabilities in client-side libraries, integrated with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Client side components might have vulnerabilities.",
    "Measure": "Tests for known vulnerabilities in components via Software Composition Analysis of the frontend are performed.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Medium",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Software Composition Analysis (server side)",
    "Level": "2",
    "Description": "Software Composition Analysis (SCA) for the server side involves examining server-side dependencies and libraries to detect and address known vulnerabilities and license compliance issues. This ensures that server applications are secure and legally compliant. Tools like Snyk, Black Duck, and OWASP Dependency-Check can be integrated into DevSecOps pipelines to automate the analysis and management of server-side software components.",
    "Tools": [
      {
        "Name": "Snyk",
        "Description": "Scans server-side dependencies for vulnerabilities and license issues, integrating seamlessly with CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Black Duck",
        "Description": "Provides comprehensive SCA for server-side libraries, automating vulnerability detection and license compliance within DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OWASP Dependency-Check",
        "Description": "An open-source SCA tool that identifies vulnerabilities in server-side dependencies, compatible with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Server side components might have vulnerabilities.",
    "Measure": "Tests for known vulnerabilities in server side components (e.g. backend/middleware) are performed.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "High",
    "Usefulness": "",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Static analysis for all components/libraries",
    "Level": "5",
    "Description": "Static analysis for all components and libraries involves thoroughly examining the entire codebase, including all third-party libraries, to identify and remediate security vulnerabilities, code quality issues, and compliance violations. This comprehensive approach ensures that both custom and external code maintain high standards of security and performance. Tools like SonarQube, Fortify, and Coverity can be integrated into DevSecOps pipelines to automate the static analysis of all components and libraries during the CI/CD process.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Performs comprehensive static code analysis for code quality and security vulnerabilities, integrating seamlessly with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Offers advanced static analysis for identifying vulnerabilities in all components and libraries, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Coverity",
        "Description": "Provides in-depth static analysis for a wide range of languages and libraries, integrated into CI/CD pipelines for continuous quality assurance.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Used components like libraries and legacy applications might have vulnerabilities",
    "Measure": "Usage of a static analysis for all used components.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Very High",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Static analysis for all self written components",
    "Level": "4",
    "Description": "Static analysis for all self-written components involves evaluating custom-developed code to identify security vulnerabilities, code quality issues, and adherence to coding standards. This ensures that internally developed components are secure and maintainable. Tools like SonarQube, ESLint, and PMD can be integrated into DevSecOps pipelines to automate the static analysis of self-written components during the CI/CD process.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Performs static code analysis for custom-developed components, integrating seamlessly with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "ESLint",
        "Description": "Analyzes JavaScript code for quality and security issues in self-written components, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "PMD",
        "Description": "Detects code quality issues and potential vulnerabilities in custom-developed code, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Parts in the source code of the frontend or middleware have vulnerabilities.",
    "Measure": "Usage of static analysis tools for all parts of the middleware and frontend. Static analysis uses for example string matching algorithms and/or dataflow analysis.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Static analysis for important client side components",
    "Level": "3",
    "Description": "Static analysis for important client-side components involves scrutinizing critical parts of the client-side codebase to identify and address security vulnerabilities and code quality issues. This ensures that essential client-side functionalities are robust and secure. Tools like ESLint, StyleCop, and SonarQube can be integrated into DevSecOps pipelines to automate the static analysis of key client-side components during the CI/CD process.",
    "Tools": [
      {
        "Name": "ESLint",
        "Description": "Analyzes JavaScript code for security and quality issues in important client-side components, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": ["JavaScript"]
      },
      {
        "Name": "StyleCop",
        "Description": "Enforces C# coding styles and best practices in important client-side components, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": ["C#"]
      },
      {
        "Name": "SonarQube",
        "Description": "Performs static code analysis for critical client-side components, ensuring security and quality within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Important parts in the source code of the frontend have vulnerabilities.",
    "Measure": "Usage of static analysis tools for important parts of the frontend are used. Static analysis uses for example string matching algorithms and/or dataflow analysis.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for applications",
    "Activity": "Static analysis for important server side components",
    "Level": "3",
    "Description": "Static analysis for important server-side components involves evaluating critical parts of the server-side codebase to detect and remediate security vulnerabilities, code quality issues, and compliance violations. This ensures that essential server-side functionalities are secure and maintainable. Tools like SonarQube, Fortify, and Coverity can be integrated into DevSecOps pipelines to automate the static analysis of key server-side components during the CI/CD process.",
    "Tools": [
      {
        "Name": "SonarQube",
        "Description": "Performs static code analysis for critical server-side components, ensuring security and quality within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fortify",
        "Description": "Provides advanced static analysis for identifying vulnerabilities in important server-side components, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Coverity",
        "Description": "Offers in-depth static analysis for critical server-side code, integrated into CI/CD pipelines for continuous quality assurance.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Important parts in the source code of the middleware have vulnerabilities.",
    "Measure": "Usage of static analysis tools for important parts of the middleware are used. Static analysis uses for example string matching algorithms and/or dataflow analysis.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Medium",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Software Composition Analysis",
    "Level": "4",
    "Description": "Software Composition Analysis (SCA) involves scanning and analyzing third-party libraries and dependencies to identify known vulnerabilities and license compliance issues. Implementing SCA ensures that all components used within the infrastructure are secure and legally compliant. Tools like Snyk, Black Duck, and OWASP Dependency-Check can be integrated into DevSecOps pipelines to automate the identification and remediation of vulnerabilities in dependencies.",
    "Tools": [
      {
        "Name": "Snyk",
        "Description": "Monitors and scans dependencies for vulnerabilities, integrating with CI/CD pipelines to ensure libraries are up-to-date and secure.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Black Duck",
        "Description": "Provides comprehensive SCA for server-side libraries, automating vulnerability detection and license compliance within DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "OWASP Dependency-Check",
        "Description": "An open-source SCA tool that identifies vulnerabilities in server-side dependencies, compatible with CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Known vulnerabilities in infrastructure components like container images might get exploited.",
    "Measure": "Check for known vulnerabilities",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.6.1",
    "ISO 27001:2022": "8.8"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Logging",
    "Activity": "Logging of security events",
    "Level": "2",
    "Description": "Logging of security events involves capturing and storing security-related activities and incidents within the system. This practice is crucial for auditing, compliance, and forensic investigations. Tools like Logstash, Fluentd, and Splunk can be integrated into DevSecOps pipelines to automate the logging of security events.",
    "Tools": [
      {
        "Name": "Logstash",
        "Description": "A data processing pipeline that ingests, transforms, and sends logs to centralized repositories, integrated into CI/CD pipelines for security event logging.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Fluentd",
        "Description": "An open-source data collector for unified logging layers, facilitating the logging of security events within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Splunk",
        "Description": "A comprehensive platform for searching, monitoring, and analyzing machine-generated data, including security events, compatible with DevSecOps pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "* No track of security-relevant events makes it harder to analyze an incident. * Security incident analysis takes significantly less time with proper security events, such that an attack can be stopped before the attacker reaches his goal.",
    "Measure": "Security-relevant events like login/logout or creation, change, deletion of users should be logged.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "Very High",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "8.15"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Simple application metrics",
    "Level": "1",
    "Description": "Simple application metrics involve tracking basic performance indicators of applications, such as response times, error rates, and throughput. These metrics provide foundational insights into application performance and health. Tools like Prometheus, Grafana, and New Relic can be integrated into DevSecOps pipelines to automate the collection and visualization of simple application metrics.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that collects and stores simple application metrics, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that creates dashboards for displaying simple application metrics, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "New Relic",
        "Description": "A monitoring and observability platform that tracks simple application metrics, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Attacks on an application are not recognized.",
    "Measure": "Gathering of application metrics helps to identify incidents like brute force attacks, login/logout.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "12.4.1",
    "ISO 27001:2022": "8.15"
  },
  {
    "Dimension": "Test and Verification",
    "Sub Dimension": "Static depth for infrastructure",
    "Activity": "Test for malware",
    "Level": "3",
    "Description": "Testing for malware involves scanning and analyzing infrastructure components to detect and remediate malicious software or code. This ensures that the infrastructure remains secure and free from malware threats. Tools like ClamAV, Malwarebytes, and Sophos can be integrated into DevSecOps pipelines to automate malware detection and removal processes.",
    "Tools": [
      {
        "Name": "ClamAV",
        "Description": "An open-source antivirus engine for detecting malware, integrated into CI/CD pipelines for automated malware scanning.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Malwarebytes",
        "Description": "Provides advanced malware detection and removal capabilities, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Sophos",
        "Description": "Offers comprehensive malware protection and scanning tools, integrated into CI/CD pipelines for continuous security.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Third party might include malware. Ether due to the maintainer (e.g. typo squatting of an image name and using the wrong image) or by an attacker on behalf of the maintainer with stolen credentials.",
    "Measure": "Check for malware in components (e.g. container images, VM baseline images, libraries).",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "V-ST-2-A",
    "ISO 27001:2017": "12.2.1",
    "ISO 27001:2022": "8.7"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Advanced availability and stability metrics",
    "Level": "3",
    "Description": "Advanced availability and stability metrics involve tracking detailed performance indicators to assess the reliability and resilience of systems. This includes metrics like uptime, latency, error rates, and resource utilization. Tools like Prometheus, Grafana, and Datadog can be integrated into DevSecOps pipelines to automate the collection and visualization of advanced availability and stability metrics, enabling proactive system management.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that collects and stores advanced availability and stability metrics, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that creates dashboards for displaying advanced availability and stability metrics, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "A monitoring and analytics platform that tracks advanced availability and stability metrics, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Trends and advanced attacks are not detected.",
    "Measure": "Advanced metrics are gathered in relation to availability and stability. For example unplanned downtime's per year.",
    "Knowledge": "High (two disciplines)",
    "Resources": "Medium",
    "Time": "High",
    "Usefulness": "Very High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Monitoring of costs",
    "Level": "2",
    "Description": "Monitoring of costs involves tracking and analyzing the financial expenditures related to infrastructure and application deployments. This practice helps in optimizing resource usage and managing budgets effectively. Tools like AWS Cost Explorer, Azure Cost Management, and Google Cloud Cost Management can be integrated into DevSecOps pipelines to automate the monitoring and reporting of infrastructure and application costs.",
    "Tools": [
      {
        "Name": "AWS Cost Explorer",
        "Description": "Provides detailed insights into AWS spending and resource usage, integrated into CI/CD pipelines for automated cost monitoring.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Azure Cost Management",
        "Description": "Offers comprehensive cost tracking and management for Azure resources, compatible with DevSecOps workflows.",
        "Opensource": false,
        "Languages": []
      },
      {
        "Name": "Google Cloud Cost Management",
        "Description": "Provides tools for tracking and optimizing Google Cloud expenditures, integrated into CI/CD pipelines for automated cost monitoring.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Not monitoring costs might lead to unexpected high resource consumption and a high invoice.",
    "Measure": "Implement cost budgets. Setting of an alert threshold and sending out errors when it is reached. In the best case, a second threshold with a limit is set so that the cost can not go higher.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Simple budget metrics",
    "Level": "1",
    "Description": "Simple budget metrics involve tracking basic financial indicators related to project or infrastructure spending. This includes metrics like monthly expenses, budget adherence, and cost forecasts. Tools like Grafana, Prometheus, and basic reporting features of cloud providers can be integrated into DevSecOps pipelines to automate the collection and visualization of simple budget metrics.",
    "Tools": [
      {
        "Name": "Grafana",
        "Description": "A visualization tool that can display simple budget metrics through customizable dashboards, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that can be configured to collect simple budget metrics within CI/CD workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Cloud Provider Reporting",
        "Description": "Basic reporting features of cloud providers (e.g., AWS Cost Explorer, Azure Cost Management) can be used to track simple budget metrics, integrated into CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Not getting notified about reaching the end of the budget (e.g. due to a denial of service) creates unexpected costs.",
    "Measure": "Cloud providers often provide insight into budgets. A threshold and alarming for the budget is set.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Low",
    "Time": "Low",
    "Usefulness": "",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Simple system metrics",
    "Level": "1",
    "Description": "Simple system metrics involve tracking fundamental performance indicators of system components, such as CPU usage, memory consumption, and disk I/O. These metrics provide basic insights into system health and performance. Tools like Prometheus, Grafana, and Nagios can be integrated into DevSecOps pipelines to automate the collection and visualization of simple system metrics.",
    "Tools": [
      {
        "Name": "Prometheus",
        "Description": "An open-source monitoring and alerting toolkit that collects simple system metrics, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Grafana",
        "Description": "A visualization tool that creates dashboards for displaying simple system metrics, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Nagios",
        "Description": "An open-source monitoring system that tracks simple system metrics and alerts on predefined conditions within CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      }
    ],
    "Risk": "Without simple metrics analysis of incidents are hard. In case an application uses a lot of CPU from time to time, it is hard for a developer to find out the source with Linux commands.",
    "Measure": "Gathering of system metrics helps to identify incidents and specially bottlenecks like in CPU usage, memory usage and hard disk usage.",
    "Knowledge": "Medium (two disciplines)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "",
    "SAMM": "O-IM-1-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6"
  },
  {
    "Dimension": "Information Gathering",
    "Sub Dimension": "Monitoring",
    "Activity": "Visualized metrics",
    "Level": "2",
    "Description": "Visualized metrics involve presenting monitoring data in graphical formats, such as charts and dashboards, to facilitate easier analysis and decision-making. This enhances the ability to quickly interpret complex data and identify trends or anomalies. Tools like Grafana, Kibana, and Datadog can be integrated into DevSecOps pipelines to automate the visualization of various metrics.",
    "Tools": [
      {
        "Name": "Grafana",
        "Description": "A visualization tool that creates interactive dashboards for displaying various metrics, integrated into CI/CD pipelines.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Kibana",
        "Description": "A visualization tool for Elasticsearch that creates interactive dashboards and graphs from log and metric data, compatible with DevSecOps workflows.",
        "Opensource": true,
        "Languages": []
      },
      {
        "Name": "Datadog",
        "Description": "A monitoring and analytics platform that provides advanced visualization capabilities for various metrics within CI/CD pipelines.",
        "Opensource": false,
        "Languages": []
      }
    ],
    "Risk": "Not visualized metrics lead to restricted usage of metrics.",
    "Measure": "Metrics are visualized in real time in a user friendly way.",
    "Knowledge": "Low (one discipline)",
    "Resources": "Medium",
    "Time": "Medium",
    "Usefulness": "High",
    "SAMM": "O-IM-2-A",
    "ISO 27001:2017": "11/30/2003",
    "ISO 27001:2022": "8.6"
  }
]
